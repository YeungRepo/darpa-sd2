{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "from deep_KO_learning import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading trained network ### \n",
    "\n",
    "script_dir = os.path.dirname('deep_KO_learning.py') # getting relative path\n",
    "trained_models_path = os.path.join(script_dir, 'trained_models') # which relative path do you want to see\n",
    "data_path = os.path.join(script_dir,'data/')\n",
    "\n",
    "netsize_dir = trained_models_path + '/mt_poly_bt_netsize.pickle' # contains the shape of network\n",
    "net_dir = trained_models_path+'/mt_poly_bt_net.pt' # contains params of network\n",
    "\n",
    "NUM_INPUTS,NUM_OUTPUTS,HL_SIZES = pickle.load(open(netsize_dir,'rb'))\n",
    "\n",
    "model = Net(NUM_INPUTS,NUM_OUTPUTS,HL_SIZES)\n",
    "model.load_state_dict(torch.load(net_dir))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading corresponding dataset ###\n",
    "\n",
    "file_dir = 'mt_poly_bt_TPMs.p' # dataset\n",
    "\n",
    "def get_snapshot_matrices(X,nT,nTraj): \n",
    "    '''This function assumes the global snapshot matrix is constructed with trajectories \n",
    "        sequentially placed in the columns'''\n",
    "    prevInds = [x for x in range(0,nT-1)]\n",
    "    forInds = [x for x in range(1,nT)]\n",
    "    for i in range(0,nTraj-1):\n",
    "        if i == 0:\n",
    "            more_prevInds = [x + nT for x in prevInds]\n",
    "            more_forInds = [x + nT for x in forInds]\n",
    "        else: \n",
    "            more_prevInds = [x + nT for x in more_prevInds]\n",
    "            more_forInds = [x + nT for x in more_forInds]\n",
    "        prevInds = prevInds + more_prevInds\n",
    "        forInds = forInds + more_forInds\n",
    "    Xp = X[:,prevInds]\n",
    "    Xf = X[:,forInds]\n",
    "    return Xp,Xf\n",
    "\n",
    "X,nT,nTraj = pickle.load(open(data_path+file_dir,'rb'))\n",
    "Xp,Xf = get_snapshot_matrices(X,nT,nTraj)\n",
    "trainXp = torch.Tensor(Xp.T)\n",
    "trainXf = torch.Tensor(Xf.T)\n",
    "testX = torch.Tensor(X.T)\n",
    "\n",
    "numDatapoints = nT*nTraj # number of total snapshots\n",
    "\n",
    "print('Dimension of the state: ' + str(trainXp.shape[1]));\n",
    "print('Number of trajectories: ' + str(nTraj));\n",
    "print('Number of total snapshots: ' + str(nT*nTraj));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = model.linears[-1].weight[:].detach().numpy()\n",
    "PsiX_test = (model(testX)['PsiXf']).detach().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "\n",
    "numStates = NUM_INPUTS\n",
    "traj = np.random.randint(0,nTraj) # np.random.randint(0,nTraj/2)\n",
    "init_index = traj*(nT)\n",
    "\n",
    "predHorizon = nT\n",
    "PsiX_pred = np.zeros((K.shape[0],predHorizon))\n",
    "for i in range(0,predHorizon):\n",
    "    PsiX_pred[:,i:i+1] = np.dot(np.linalg.matrix_power(K,i),PsiX_test[:,init_index:init_index+1]) \n",
    "\n",
    "mse = np.linalg.norm(PsiX_test[:,init_index:init_index+predHorizon] - PsiX_pred,'fro')/np.linalg.norm(PsiX_test[:,init_index:init_index+predHorizon],'fro')\n",
    "print('Trajectory ' + str(traj) + ', MSE: ' + str(round(mse,5)))\n",
    "\n",
    "truthLeg = mlines.Line2D([], [], color='black',linestyle='',marker='.',label='Truth')\n",
    "predLeg = mlines.Line2D([], [], color='black',linestyle='-',label='Predicted')\n",
    "numCurves = 10 # how many gene preds do you want to plot?\n",
    "plotStates = np.random.randint(1,numStates-1,numCurves)\n",
    "plt.figure(figsize=(10,5));\n",
    "for i in range(0,len(plotStates)):\n",
    "    plt.plot(PsiX_test[plotStates[i],init_index:init_index+predHorizon],'o',ms=12,lw=3);\n",
    "    plt.plot(PsiX_pred[plotStates[i],0:predHorizon],'--',ms=10,lw=4);\n",
    "    plt.legend(handles=[truthLeg,predLeg]);\n",
    "#     plt.ylabel(r'$\\mathbf{x}$'+r'_{'+str(i)+r'}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A better prediction calculation ###\n",
    "\n",
    "PsiX_pred = np.zeros((K.shape[0],numDatapoints))\n",
    "trajInds = [x for x in range(0,nT)]\n",
    "trajInds = [trajInds for x in range(0,nTraj)]\n",
    "trajInds = [j for i in trajInds for j in i] \n",
    "count = 0\n",
    "initInd = 0\n",
    "for i in range(0,nTraj):\n",
    "    psix_test_ic = PsiX_test[:,i*nT:i*nT+1]\n",
    "    for j in range(0,nT):\n",
    "        PsiX_pred[:,count:count+1] = np.dot(np.linalg.matrix_power(K,j),psix_test_ic) \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### storing the mean squared errors for each gene (row) ###\n",
    "per_gene_mse = []\n",
    "for k in range(1,NUM_INPUTS+1):\n",
    "    den = np.linalg.norm(PsiX_test[k,:],ord=2)\n",
    "    if den == 0.0:\n",
    "        den = 1\n",
    "    dist = np.linalg.norm(PsiX_pred[k,:] - PsiX_test[k,:],ord=2)/den\n",
    "    if np.isinf(dist):\n",
    "        dist = 0\n",
    "    per_gene_mse.append(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mu = np.mean(X,axis=1)\n",
    "\n",
    "fig, ax1 = plt.subplots();\n",
    "left, bottom, width, height = [0.65, 0.6, 0.2, 0.2]\n",
    "ax2 = fig.add_axes([left, bottom, width, height]);\n",
    "ax1.plot(per_gene_mse);\n",
    "ax1.plot(np.abs(total_mu));\n",
    "ax2.plot(per_gene_mse);\n",
    "# ax2.plot(np.abs(total_mu));\n",
    "# ax2.set_xlim([80,120]);\n",
    "# ax2.set_ylim([0.00005,0.0006])\n",
    "# plt.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.dot(PsiX_pred,PsiX_test.T)\n",
    "# for i in range(0,testX.shape[1]): \n",
    "#     if corr[i,i] == 0.0:\n",
    "#         corr[i,i] = 1\n",
    "\n",
    "# plt.figure(figsize=(15,7));\n",
    "# ax = sn.heatmap(corr[1:testX.shape[1]+1,1:testX.shape[1]+1],cmap='magma');\n",
    "# ax = sn.heatmap(corr[100:200,100:200],cmap='magma');\n",
    "plt.figure();\n",
    "sn.clustermap(corr[1:testX.shape[1]+1,1:testX.shape[1]+1],cmap='magma',figsize=(15,15));\n",
    "# plt.savefig('correlation_pred_actual.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(0,2*math.pi,100)\n",
    "plt.figure(figsize=(6,5));\n",
    "plt.plot(np.real(np.linalg.eigvals(K)),np.imag(np.linalg.eigvals(K)),'o',ms=10);\n",
    "plt.plot(np.cos(theta),np.sin(theta),color='black');\n",
    "plt.ylabel('$Imag(\\lambda)$');\n",
    "plt.xlabel('$Real(\\lambda)$');\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_SamplingMat(K,nOutputs):\n",
    "    nObs = K.shape[0]\n",
    "    evals, evecs = np.linalg.eig(K)\n",
    "    SamplingMat = np.dot(np.concatenate((np.identity(nOutputs),np.zeros((nOutputs,nObs-nOutputs))),axis=1),np.linalg.inv(evecs))\n",
    "    return SamplingMat\n",
    "\n",
    "nOutputs = int(X.shape[0]/5) \n",
    "Wh = calc_SamplingMat(K,nOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sensitivity analysis ###\n",
    "\n",
    "def calc_SensitivityMat(Wh,net,X_global,nGridpts,nOutputs):\n",
    "    ''' Output sensitivity matrix is calculated by perturbing a single element of the state at a \n",
    "        time, computing the resulting outputs, subtracting the mean output from the resulting outputs,\n",
    "        and finally averaging over the mean subtracted resultant outputs. \n",
    "    '''\n",
    "    X_mean = np.mean(X_global,axis=1).reshape(X_global.shape[0],1) # the reference values\n",
    "    PsiX_mean = (net(torch.Tensor(X_mean.T))['PsiXf']).detach().numpy().T \n",
    "    X_std = np.std(X,axis=1).reshape(X.shape[0],1)\n",
    "    \n",
    "    y_mean = np.dot(Wh,PsiX_mean)\n",
    "    \n",
    "    X_range = np.zeros((len(X_mean),nGridpts))\n",
    "    for i in range(0,len(X_mean)):\n",
    "        X_range[i,:] = np.linspace(X_mean[i]-X_std[i],X_mean[i]+X_std[i],nGridpts).T\n",
    "        \n",
    "    from copy import deepcopy\n",
    "    S = np.zeros((nOutputs,X_global.shape[0]),dtype=complex) # sensitivity matrix \n",
    "    for s in range(0,S.shape[1]):\n",
    "        X_sens = deepcopy(X_mean)\n",
    "        Y = np.zeros((nOutputs,nGridpts),dtype=complex)\n",
    "        for i in range(0,nGridpts): # looping through the various perturbations of state s\n",
    "            X_sens[s,:] = X_range[s,i]\n",
    "            PsiX_sens = (net(torch.Tensor(X_sens.T))['PsiXf']).detach().numpy().T    \n",
    "            Y_sens = np.dot(Wh,PsiX_sens)\n",
    "            Y[:,i:i+1] = Y_sens - y_mean # Take away y(x_mean) from every column of Y_sens\n",
    "        S[:,s] = np.mean(Y,axis=1)\n",
    "\n",
    "    # normalizing S to be between 0 and 1. \n",
    "    S = S/np.max(S)\n",
    "    for i in range(S.shape[0]):\n",
    "        for j in range(S.shape[1]):\n",
    "            S[i,j] = np.linalg.norm(S[i,j])\n",
    "            \n",
    "    return S.real\n",
    "\n",
    "nGridpts = 100\n",
    "S = calc_SensitivityMat(Wh,model,X,nGridpts,nOutputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,7));\n",
    "# ax = sn.heatmap(S,cmap='magma');\n",
    "plt.figure();\n",
    "clustergrid = sn.clustermap(S,cmap='magma',figsize=(15,15));\n",
    "# plt.savefig('bt_Wh_clustermap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Which genes impact the output the most? ###\n",
    "\n",
    "names_dir = 'mt_poly_bt_geneNames.p'\n",
    "gene_names = list(pickle.load(open(data_path+names_dir,'rb')))\n",
    "\n",
    "perm_col_inds = clustergrid.dendrogram_col.reordered_ind # permuted column indices\n",
    "sensGenes = [gene_names[i] for i in perm_col_inds[0:10]] # 10 of them \n",
    "sensInds = []\n",
    "for i in range(len(sensGenes)):\n",
    "    sensInds.append(gene_names.index(sensGenes[i]))\n",
    "print(sensGenes)\n",
    "print(sensInds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### magic six ### \n",
    "'''This is only for Pseudomonas fluorescens'''\n",
    "\n",
    "md = 'malate dehydrogenase CDS'\n",
    "akd = 'alpha-ketoacid dehydrogenase subunit beta CDS'\n",
    "eat = 'ethanolamine ammonia-lyase subunit EutB CDS'\n",
    "ivcd = 'isovaleryl-CoA dehydrogenase CDS'\n",
    "# topa = 'topA CDS' filtered out for whatever reason (using the data where lanes and reads are treated seperately)\n",
    "clpx = 'clpX CDS' \n",
    "\n",
    "print(gene_names.index(md),gene_names.index(akd),gene_names.index(eat),gene_names.index(ivcd),gene_names.index(clpx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
