{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; \n",
    "import matplotlib.pyplot as plt; \n",
    "%matplotlib inline\n",
    "import os, sys\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "#JU_frame = pd.read_csv('/home/jupyter/sd2e-community/ginkgo/novel-chassis/201808/Novelchassis-Nand-Gate/normal_library_prep/dataframes/star/ReadCountMatrix_preCAD.tsv',sep='\\t');\n",
    "JU_frame = pd.read_csv('NAND_Chassis_RNAseq_preCAD_TPM.tsv',sep='\\t');                        \n",
    "#                       201808/Novelchassis-Nand-Gate/normal_library_prep/dataframes/bowtie2/ReadCountMatrix_preCAD.tsv',sep='\\t');\n",
    "#JU_frame = pd.read_csv('/home/jupyter/sd2e-community/shared-q1-workshop/usaxena/reorded_bwa_ginkgo_normal_prep/Reordered_ReadCountMatrix_preCAD_FPKM.csv')\n",
    "#https://jupyter.sd2e.org/user/eyeung/tree/sd2e-community/shared-q1-workshop/usaxena/reorded_bwa_ginkgo_normal_prep\n",
    "#pd.read_csv('/home/jupyter/sd2e-community/ginkgo/novel-chassis/201808/Novelchassis-Nand-Gate/normal_library_prep/dataframes/star/'\n",
    "                       \n",
    "                       \n",
    "#print(JU_frame.columns)                       \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_column_names = JU_frame.columns;\n",
    "\n",
    "# For parsing TACC columns \n",
    "new_column_names = [None]*len(all_column_names);\n",
    "new_column_names[0] = all_column_names[0];\n",
    "for col_ind in range(1,len(all_column_names)):\n",
    "    column_name = str(all_column_names[col_ind]);\n",
    "    #print(column_name)\n",
    "    this_id = column_name.split('.')[-1];\n",
    "    #print(this_id)\n",
    "    new_column_names[col_ind] = this_id;\n",
    "clear_JU_frame = pd.DataFrame(JU_frame);\n",
    "clear_JU_frame.columns=new_column_names;#JU_frame.columns;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Synthetic_Genes = clear_JU_frame.gene_id[4098:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dict_file = open('dict_files.pickle','rb')\n",
    "dict_list = pickle.load(dict_file);\n",
    "strain_to_ids_dict = dict_list[0];\n",
    "cond_dict = dict_list[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear_JU_frame.to_csv('Floated_Reordered_ReadCountMatrix_preCAD_Normal_TPM.csv')\n",
    "clear_JU_frame = pd.read_csv('Floated_Reordered_ReadCountMatrix_preCAD_Normal_TPM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "all_strains = strain_to_ids_dict.keys();\n",
    "master_dict = dict();\n",
    "for this_strain_id in all_strains:\n",
    "    wt_ids = list(set(strain_to_ids_dict[this_strain_id]));\n",
    "    \n",
    "    data_by_cond_dict = dict();\n",
    "    for wt_id in wt_ids:\n",
    "        cond_num = cond_dict[wt_id];\n",
    "        if cond_num[0]>0.0:\n",
    "            ara_state = '1';\n",
    "        else:\n",
    "            ara_state = '0';\n",
    "        if cond_num[1]>0.0:\n",
    "            iptg_state = '1';\n",
    "        else:\n",
    "            iptg_state = '0';\n",
    "        \n",
    "        temperature=repr(int(cond_num[2]));\n",
    "        timepoint = repr(int(cond_num[3]));\n",
    "        replicate_num = repr(int(cond_num[4]));\n",
    "        \n",
    "        cond_key = ara_state+iptg_state+temperature+timepoint+ replicate_num;\n",
    "        #print(wt_id)\n",
    "        if wt_id in clear_JU_frame.columns:\n",
    "            data_for_condition = clear_JU_frame[wt_id].values;\n",
    "            #data_for_condition[data_for_condition<40] = 0.0;\n",
    "            #print(data_for_condition.shape)\n",
    "            for ind in range(0,data_for_condition.shape[0]):\n",
    "                data_for_condition = data_for_condition;    \n",
    "\n",
    "            if this_strain_id in master_dict.keys():\n",
    "                if cond_key in master_dict[this_strain_id].keys():\n",
    "                    master_dict[this_strain_id][cond_key].append(data_for_condition);    \n",
    "                else:    \n",
    "                    master_dict[this_strain_id][cond_key] = [data_for_condition];\n",
    "\n",
    "            else:\n",
    "                master_dict[this_strain_id] = dict(); \n",
    "                if cond_key in master_dict[this_strain_id].keys():\n",
    "                    master_dict[this_strain_id][cond_key].append(data_for_condition);    \n",
    "                else:    \n",
    "                    master_dict[this_strain_id][cond_key] = [data_for_condition];\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepair_list = [];\n",
    "for ind_cond in ['00']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_FKPM = 3e4;\n",
    "all_genes = clear_JU_frame['gene_id'];\n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "\n",
    "    \n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "#%autoreload\n",
    "viz_this_set = True; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['01']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "#T1_list = T1_list_log;\n",
    "#T2_list = T2_list_log;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Genes with Noise Higher Than Signal, Filtering (Fast Timescale) Steady-State Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for sub_rep in [[0,1,2,3]]:\n",
    "for sub_rep in [[0,1,2],[0,1,3],[1,2,3],[0,2,3],[0,1,2,3] ]:\n",
    "#     plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "    mu_t1 = np.mean(T1_list[sub_rep][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[sub_rep][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[sub_rep][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[sub_rep][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    low_cv_indices = [];\n",
    "    for k in range(0,len(mu_t1)):\n",
    "        good_cv = True;\n",
    "        if mu_t1[k]>0.0:\n",
    "            cv1[k] = s_t1[k]/mu_t1[k];\n",
    "            if cv1[k]>0.1:\n",
    "                good_cv = False;\n",
    "        else:\n",
    "            good_cv = False;\n",
    "        if mu_t2[k]>0.0:\n",
    "            cv2[k] = s_t2[k]/mu_t2[k];\n",
    "            if cv2[k]>0.1:\n",
    "                good_cv = False;\n",
    "        else:\n",
    "            good_cv=False;\n",
    "            \n",
    "        if mu_t1[k]>0.0 and mu_t2[k]>0.0:\n",
    "            if np.abs(mu_t1[k]/ mu_t2[k] -1.0) <0.3:\n",
    "                good_cv = False;\n",
    "        \n",
    "        if good_cv:\n",
    "            low_cv_indices.append(k);\n",
    "    #print(all_genes[low_cv_indices]);\n",
    "\n",
    "    #plt.scatter((mu_t1),cv1,alpha=0.1);\n",
    "    #plt.scatter((mu_t2),cv2,alpha=0.1);\n",
    "\n",
    "    \n",
    "#    plt.scatter(np.arange(0,T1_list.shape[1],1),cv1,alpha=0.1);\n",
    "#    plt.scatter(np.arange(0,T2_list.shape[1],1),cv2,alpha=0.1);\n",
    "    #ax = plt.gca();\n",
    "    #ax.spines['right'].set_visible(False)\n",
    "    #ax.spines['top'].set_visible(False)\n",
    "    #sub_rep_str = [str(elem) for elem in sub_rep]\n",
    "    #plt.legend(['Samples '+','.join(sub_rep_str)+' @ 5 hr','Samples ' + ','.join(sub_rep_str)+' @ 18 hr'] )\n",
    "    #plt.ylim([-.05,0.6])\n",
    "    #plt.ylabel('Coefficient of Variation (s/µ)')\n",
    "    #plt.xlabel('Mean of FPKM (log)')\n",
    "#plt.errorbar(np.arange(0,T2_list.shape[1],1),np.std(T2_list,axis=0)/np.mean(T2_list,axis=0) );\n",
    "#plt.errorbar(np.arange(0,T2_list.shape[1],1), np.mean(T2_list,axis=0), yerr=np.std(T2_list,axis=0));\n",
    "#plt.ylim([0,1e4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of genes with low FPKM CV: 429\n"
     ]
    }
   ],
   "source": [
    "print(\"# of genes with low FPKM CV: \" + repr(len(low_cv_indices)))\n",
    "#print(\"# of genes with low FPKM CV: \" + repr(len(all_genes)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x127fb3c40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtyseven_low_cv_indices = low_cv_indices;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "araD\n",
      "araA\n",
      "araB\n",
      "araC\n",
      "araJ\n",
      "araH\n",
      "araG\n",
      "araF\n",
      "araE\n",
      "lacA\n",
      "lacY\n",
      "lacZ\n",
      "lacI\n"
     ]
    }
   ],
   "source": [
    "lac_indices = [];\n",
    "for ind in range(0,len(all_genes)):\n",
    "    if 'lac' in str(all_genes[ind]):#.lower():\n",
    "        lac_indices.append(ind)\n",
    "\n",
    "ara_indices = [];\n",
    "for ind in range(0,len(all_genes)):\n",
    "    if 'ara' in str(all_genes[ind]):#.lower():\n",
    "        ara_indices.append(ind)  \n",
    "        \n",
    "for ind in ara_indices:\n",
    "    print(all_genes[ind])\n",
    "    \n",
    "for ind in lac_indices:\n",
    "    print(all_genes[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4107 - Circuit_PhlF\n",
    "# 4119 - Actuator_YFP\n",
    "# 4126 - Circuit_IcaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_ids = list(np.arange(4098,len(all_genes)))#list(np.arange(0,13,1))\n",
    "circuit_names = list(all_genes)[circuit_ids[0]:(circuit_ids[-1]+1)]\n",
    "\n",
    "# circuit_ids_sel = list([4107, 4119, 4126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common_indices = list(set(thirtyseven_low_cv_indices).intersection( set(thirty_low_cv_indices) ));\n",
    "common_indices = thirtyseven_low_cv_indices # 429 genes with low_cv\n",
    "# common_indices = ara_indices + lac_indices # 13 or so genes of the lac and ara operons\n",
    "# common_indices = ara_indices+lac_indices+circuit_ids; # including circuit components\n",
    "# common_indices = ara_indices + lac_indices + circuit_ids_sel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "# for col_ind in [0,2,3]:\n",
    "#     plt.bar(np.arange(1,len(circuit_ids),1),T2_list.T[circuit_ids[0]:circuit_ids[-1],col_ind],alpha=0.25)\n",
    "    \n",
    "# ax = plt.gca()\n",
    "# ax.set_xticks(np.arange(1,len(circuit_ids),1))\n",
    "# ax.set_xticklabels(circuit_names,rotation=-90,fontsize=14)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# plt.legend(['Replicate 0','Replicate 2','Replicate 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for ind in range(0,Yp_data.shape[1]):\n",
    "#     plt.figure()\n",
    "#     plt.scatter(Yp_data[:,ind],Yf_data[:,ind])\n",
    "#     plt.figure()\n",
    "#     plt.scatter(Yp_data[:,ind],Yp_data[:,ind-1],color='r')\n",
    "#     plt.figure()\n",
    "#     plt.scatter(Yf_data[:,ind],Yf_data[:,ind-1],color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --user cvxopt\n",
    "# from cvxopt import matrix, solvers\n",
    "# !pip3 install --user cvxpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy\n",
    "from cvxpy import Minimize\n",
    "from cvxpy import Minimize, Problem, Variable,norm1,installed_solvers,lambda_max;\n",
    "from cvxpy import norm as cvxpynorm;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Disable\n",
    "# def blockPrint():\n",
    "#     sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# # Restore\n",
    "# def enablePrint():\n",
    "#     sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload\n",
    "class Lifting:\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self,this_index_of_used_functions,this_function_dictionary,this_num_input_vars):\n",
    "        self.function_dictionary = list(this_function_dictionary);\n",
    "        self.indices_of_used_functions = list(this_index_of_used_functions);\n",
    "        self.num_input_vars = np.int(this_num_input_vars);\n",
    "        \n",
    "            \n",
    "    def eval_lifting_list(self,input_var):\n",
    "        import numpy as np;\n",
    "        evaluated_lifting = -1.0;\n",
    "        #if not (len(input_var)== self.num_input_vars):\n",
    "        #    print(\"Error: input var supplied does not match target input var size:\" + repr (self.num_input_vars));\n",
    "        #    import numpy as np;\n",
    "        #    return evaluated_lifting;\n",
    "        #else:\n",
    "        evaluated_lifting = [];\n",
    "        for dict_index in self.indices_of_used_functions:\n",
    "            this_dictionary_function = self.function_dictionary[dict_index];\n",
    "            evaluated_lifting.append(this_dictionary_function(input_var))\n",
    "\n",
    "        return evaluated_lifting;\n",
    "    \n",
    "    \n",
    "    def eval_lifting_array(self,input_var):\n",
    "        import numpy as np;\n",
    "        evaluated_lifting = -1.0\n",
    "        #if not (len(input_var)== self.num_input_vars):\n",
    "        #    print(\"Error: input var supplied does not match target input var size:\" + repr (self.num_input_vars));\n",
    "        #    import numpy as np;\n",
    "        #    return evaluated_lifting;\n",
    "\n",
    "        evaluated_lifting = [];\n",
    "        for dict_index in self.indices_of_used_functions:\n",
    "            \n",
    "            this_dictionary_function = self.function_dictionary[dict_index];\n",
    "            evaluated_lifting.append(this_dictionary_function(input_var))\n",
    "        \n",
    "        return np.asarray(evaluated_lifting).reshape((len(evaluated_lifting),1));\n",
    "\n",
    "    def append_lifting_terms(self,new_index_of_used_functions,new_function_dictionary,new_num_input_vars):\n",
    "        \n",
    "        try:\n",
    "            if len(new_index_of_used_functions) > len(new_function_dictionary):\n",
    "                raise Exception('number of indices of used functions should not exceed length of new function dictionary');\n",
    "            self.indices_of_used_functions = self.indices_of_used_functions + list(new_index_of_used_functions + len(self.function_dictionary)); \n",
    "            self.num_input_vars = self.num_input_vars + new_num_input_vars;\n",
    "            self.function_dictionary = self.function_dictionary + list(new_function_dictionary);\n",
    "            return self;\n",
    "        except (Exception):\n",
    "            return -1.0;\n",
    "        \n",
    "    def lifting_dim(self):\n",
    "        return len(self.indices_of_used_functions);\n",
    "    \n",
    "    def return_dim(self):\n",
    "        return len(self.indices_of_used_functions);\n",
    "        \n",
    "        \n",
    "    #to do for AH and NB, what other abstract properties should a lifting class have? \n",
    "#%autoreload    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blockPrint()\n",
    "# enablePrint()\n",
    "class InputKoopmanModel:\n",
    "    def __init__(self,this_K_open_loop,this_state_lifting,this_K_input,this_input_lifting):\n",
    "        self.K_open_loop = np.asarray(this_K_open_loop,dtype=np.float32)\n",
    "        self.K_input =  np.asarray(this_K_input,dtype=np.float32)\n",
    "        self.Psi_open_loop = this_state_lifting\n",
    "        self.Psi_input = this_input_lifting\n",
    "        \n",
    "        self.Kol = self.K_open_loop\n",
    "        self.Ki = self.K_input\n",
    "        self.Pol = self.Psi_open_loop\n",
    "        self.Pi = self.Psi_input\n",
    "        \n",
    "    def append_input(self,new_K_input,new_input_lifting):\n",
    "        try:\n",
    "            self.K_input = np.hstack((self.K_input,np.asarray(new_K_input,dtype=np.float32)));\n",
    "        except:\n",
    "            print(self.K_input.shape)\n",
    "            print(new_K_input.shape)\n",
    "        niuf= new_input_lifting.indices_of_used_functions;\n",
    "        niv = new_input_lifting.num_input_vars; \n",
    "        nfd = new_input_lifting.function_dictionary;    \n",
    "        self.Psi_input.append_lifting_terms(niuf,nfd,niv);\n",
    "        \n",
    "    def eval_diff(self,state_vec,input_vec):\n",
    "        return np.dot(self.Kol,self.Pol.eval_lifting_array(state_vec))+ np.dot(self.Ki,self.Pi.eval_lifting_array(input_vec));\n",
    "        \n",
    "    \n",
    "def calc_Input_Koopman(Kol,Yf,Yp,Up,flag=1,lambda_val=0.0,PsiDelta_Mat=[]):\n",
    "    solver_instance = cvxpy.SCS;\n",
    "    Ki = None;\n",
    "    if flag==1: # moore penrose inverse, plain ol' least squares input-Koopman\n",
    "        #Yp_inv = np.dot(np.transpose(Yp_final), np.linalg.inv( np.dot(Yp_final,np.transpose(Yp_final)) )   );\n",
    "        Yfprime = Yf-np.dot(Kol,Yp)\n",
    "        Up_inv = np.linalg.pinv(Up);\n",
    "        Ki = np.dot(Yfprime,Up_inv);\n",
    "        \n",
    "\n",
    "    if flag ==2: # cvx optimization approach - L2 + L1 lasso \n",
    "        norm1_term = 0.0;\n",
    "        all_col_handles = [None]*Up.shape[0]\n",
    "\n",
    "        for i in range(0,Up.shape[0]):\n",
    "            #print(Yf.shape[0])\n",
    "            all_col_handles[i] = Variable(shape=(Yf.shape[0],1)) ;#Variable(shape=(Yf.shape[0],1) );\n",
    "        #    if norm1_term < cvxpy.norm(all_col_handles[i],p=1):\n",
    "        #        norm1_term = cvxpy.norm(all_col_handles[i],p=1);\n",
    "            #norm1_term =  cvxpy.max(cvxpy.hstack( [norm1_term,cvxpy.norm(all_col_handles[i],p=1) ])  );\n",
    "        operator = cvxpy.hstack(all_col_handles);\n",
    "        \n",
    "        if len(PsiDelta_Mat) == 0:\n",
    "            if (type(lambda_val) == np.float):\n",
    "                norm1_term =lambda_val*cvxpy.norm(operator,p=2);\n",
    "            else:\n",
    "                lambda_val = np.reshape(lambda_val,(len(lambda_val),1));\n",
    "                Unoise = np.tile(lambda_val,(1,Up.shape[1]))\n",
    "                norm1_term = cvxpy.norm(cvxpy.matmul(operator,Unoise),p=2);\n",
    "        else:\n",
    "            norm1_term = cvxpy.norm(cvxpy.matmul(operator,PsiDelta_Mat),p=2);\n",
    "        \n",
    "        #operator = all_col_handles[0];\n",
    "        #for i in range(1,Yf.shape[0]):\n",
    "        #    operator = cvxpy.hstack([operator,all_col_handles[i]]);\n",
    "        #operator.\n",
    "        #print(\"[INFO]: CVXPY Koopman operator variable: \" +repr(operator.shape));\n",
    "        #print(repr(operator));\n",
    "        #print(\"[INFO]: Yf.shape in calc_Koopman: \" + repr(Yf.shape));\n",
    "        #print(\"[INFO]: Yp.shape in calc_Koopman: \" + repr(Yp.shape));\n",
    "        Yfprime = Yf-np.dot(Kol,Yp)\n",
    "        norm2_fit_term = cvxpy.norm(cvxpy.norm(Yfprime-operator*Up,p=2,axis=0),p=2);\n",
    "        objective = Minimize(norm2_fit_term + norm1_term)\n",
    "        constraints = [];\n",
    "        prob = Problem(objective,constraints);\n",
    "        result = prob.solve(verbose=False,solver=solver_instance,max_iters=np.int(1e7))#,reltol=1e-10,abstol=1e-10);\n",
    "#         print(\"[INFO]: Finished executing cvx solver, printing CVXPY problem status\")\n",
    "#         print(prob.status);\n",
    "        Ki = operator.value;\n",
    "    return Ki;\n",
    "        \n",
    "def calc_Append_Input_Koopman(Kol,Ki,Yf,Yp,Up,Uamend,flag=1,lambda_uamend_val= 0.0,PsiUp_Delta_Mat=[]):\n",
    "    solver_instance = cvxpy.SCS;\n",
    "    Kamend = None;\n",
    "    if flag==1: # moore penrose inverse, plain ol' least squares input-Koopman\n",
    "        #Yp_inv = np.dot(np.transpose(Yp_final), np.linalg.inv( np.dot(Yp_final,np.transpose(Yp_final)) )   );\n",
    "        Yfprime = Yf-np.dot(Kol,Yp)-np.dot(Ki,Up);\n",
    "        Ua_inv = np.linalg.pinv(Uamend);\n",
    "        Kamend = np.dot(Yfprime,Ua_inv);\n",
    "        \n",
    "        \n",
    "    \n",
    "    if flag ==2: # cvx optimization approach - L2 + L1 lasso \n",
    "        norm1_term = 0.0;\n",
    "        all_col_handles = [None]*Uamend.shape[0]\n",
    "        for i in range(0,Uamend.shape[0]):            \n",
    "            all_col_handles[i] = Variable(shape=(Yf.shape[0],1));#Variable(shape=(Yf.shape[0],1) );\n",
    "        \n",
    "        operator = cvxpy.hstack(all_col_handles);\n",
    "        norm1_term = 0.0;\n",
    "        if len(PsiUp_Delta_Mat) == 0:\n",
    "            if type(lambda_uamend_val) == np.float:\n",
    "                lambda_uamend_val = [lambda_uamend_val]*Uamend.shape[0];\n",
    "                lambda_uamend_val = np.reshape(lambda_uamend_val,(len(lambda_uamend_val),1));\n",
    "                Unoise = np.tile(lambda_uamend_val,(1,Uamend.shape[1]));\n",
    "            else:\n",
    "                Unoise = np.tile(lambda_uamend_val,(1,Uamend.shape[1]));\n",
    "            norm1_term = cvxpy.norm(cvxpy.matmul(operator,Unoise),p=2);\n",
    "        else:\n",
    "            norm1_term = cvxpy.norm(cvxpy.matmul(operator,PsiUp_Delta_Mat),p=2)\n",
    "        #operator = all_col_handles[0];\n",
    "        #for i in range(1,Yf.shape[0]):\n",
    "        #    operator = cvxpy.hstack([operator,all_col_handles[i]]);\n",
    "        #operator.\n",
    "        #print(\"[INFO]: CVXPY Koopman operator variable: \" +repr(operator.shape));\n",
    "        #print(repr(operator));\n",
    "        #print(\"[INFO]: Yf.shape in calc_Koopman: \" + repr(Yf.shape));\n",
    "        #print(\"[INFO]: Yp.shape in calc_Koopman: \" + repr(Yp.shape));\n",
    "        Yfprime = Yf- np.dot(Kol,Yp)-np.dot(Ki,Up)\n",
    "        norm2_fit_term = cvxpy.norm(cvxpy.norm(Yfprime-operator*Uamend,p=2,axis=0),p=2);\n",
    "        objective = Minimize(norm2_fit_term + norm1_term)\n",
    "        constraints = [];\n",
    "        prob = Problem(objective,constraints);\n",
    "        result = prob.solve(verbose=False,solver=solver_instance,max_iters=np.int(1e7))#,reltol=1e-10,abstol=1e-10);\n",
    "        print(\"[INFO]: Finished executing cvx solver, printing CVXPY problem status\")\n",
    "        print(prob.status);\n",
    "        Kamend = operator.value;\n",
    "    return Kamend;        \n",
    "\n",
    "def train_Append_Input_Koopman(Xf,Xp,unl_Up,unl_UAmend,this_InputKoopmanModel,AmendLifting,num_rawstates,num_rawinputs,num_rawamendinputs,num_snapshots):\n",
    "    if Xf.shape[1] == num_rawstates:\n",
    "        Xf = Xf.T;\n",
    "    if Xp.shape[1] ==num_rawstates:\n",
    "        Xp = Xp.T; \n",
    "    if unl_Up.shape[1] == num_rawinputs:\n",
    "        unl_Up = unl_Up.T; \n",
    "    if unl_UAmend.shape[1] == num_rawamendinputs:\n",
    "        unl_UAmend = unl_UAmend.T;\n",
    "        \n",
    "    PsiXf = np.zeros(this_InputKoopmanModel.Pol.return_dim(),Xf.shape[1]);\n",
    "    for ind in range(0,Xf.shape[1]):\n",
    "        PsiXf[:,ind] = this_InputKoopmanModel.Pol.eval_lifting_array(Xf[:,ind]);\n",
    "    \n",
    "    PsiXp = np.zeros(this_InputKoopmanModel.Pol.return_dim(),Xp.shape[1]);\n",
    "    for ind in range(0,Xp.shape[1]):\n",
    "        PsiXp[:,ind] = this_InputKoopmanModel.Pol.eval_lifting_array(Xp[:,ind]);\n",
    "    \n",
    "    PsiUp = np.zeros(this_InputKoopmanModel.Pi.return_dim(),unl_Up.shape[1]);\n",
    "    for ind in range(0,unl_Up.shape[1]):\n",
    "        PsiUp[:,ind] = this_InputKoopmanModel.Pi.eval_lifting_array(unl_Up[:,ind]);\n",
    "    \n",
    "    PsiAUp = np.zeros(AmendLifting.return_dim(),unl_UAmend.shape[1]);\n",
    "    for ind in range(0,unl_UAmend.shape[1]):\n",
    "        PsiAUp[:,ind] = AmendLifting.eval_lifting_array(unl_UAmend[:,ind]);\n",
    "    \n",
    "    this_Kol = this_InputKoopmanModel.Kol;\n",
    "    this_Ki = this_InputKoopmanModel.Ki;\n",
    "    calc_Append_Input_Koopman(this_Kol,this_Ki,PsiXf,PsiXp,PsiUp,PsiAUp,flag=1,lambda_val=0.0)\n",
    "    \n",
    "#%autoreload        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blockPrint()\n",
    "# enablePrint()\n",
    "def calc_Koopman(Yf,Yp,flag=1,lambda_val=0.0):\n",
    "    #solver_instance = cvxpy.CVXOPT;\n",
    "    solver_instance = cvxpy.SCS;\n",
    "    if flag==1: # moore penrose inverse, plain ol' least squares Koopman\n",
    "        #Yp_inv = np.dot(np.transpose(Yp_final), np.linalg.inv( np.dot(Yp_final,np.transpose(Yp_final)) )   );\n",
    "        Yp_inv = np.linalg.pinv(Yp);\n",
    "        K = np.dot(Yf,Yp_inv);\n",
    "        \n",
    "\n",
    "    if flag ==2: # cvx optimization approach - L2 + L1 lasso \n",
    "        norm1_term = 0.0;\n",
    "        all_col_handles = [None]*Yf.shape[0]\n",
    "        if type(lambda_val)== np.float:\n",
    "            lambda_val = list([lambda_val]*Yf.shape[0]);\n",
    "        \n",
    "        for i in range(0,Yf.shape[0]):                 \n",
    "            all_col_handles[i] = Variable(shape=(Yf.shape[0],1)) ;#Variable(shape=(Yf.shape[0],1) );\n",
    "\n",
    "        operator = cvxpy.hstack(all_col_handles);\n",
    "        \n",
    "        if type(lambda_val) == np.float:\n",
    "            norm1_term =lambda_val*cvxpy.norm(operator,p=2);\n",
    "        else:\n",
    "            lambda_val = np.reshape(lambda_val,(len(lambda_val),1));\n",
    "            Unoise = np.tile(lambda_val,(1,Yf.shape[1]));\n",
    "            norm1_term = cvxpy.norm(cvxpy.matmul(operator + np.eye(Yf.shape[0]),Unoise),p=2);\n",
    "\n",
    "\n",
    "        #operator = all_col_handles[0];\n",
    "        #for i in range(1,Yf.shape[0]):\n",
    "        #    operator = cvxpy.hstack([operator,all_col_handles[i]]);\n",
    "        #operator.\n",
    "        #print(\"[INFO]: CVXPY Koopman operator variable: \" +repr(operator.shape));\n",
    "        #print(repr(operator));\n",
    "        #print(\"[INFO]: Yf.shape in calc_Koopman: \" + repr(Yf.shape));\n",
    "        #print(\"[INFO]: Yp.shape in calc_Koopman: \" + repr(Yp.shape));\n",
    "        norm2_fit_term = cvxpy.norm(cvxpy.norm(Yf-operator*Yp,p=2,axis=0),p=2);\n",
    "        objective = Minimize(norm2_fit_term + norm1_term)\n",
    "        constraints = [];\n",
    "        prob = Problem(objective,constraints);\n",
    "        result = prob.solve(verbose=False,solver=solver_instance,max_iters=np.int(1e7))#,reltol=1e-10,abstol=1e-10);\n",
    "        print(\"[INFO]: Finished executing cvx solver, printing CVXPY problem status\")\n",
    "        print(prob.status);\n",
    "        K = operator.value;\n",
    "\n",
    "    if flag ==3:\n",
    "        operator = Variable(Yf.shape[0],Yf.shape[0])\n",
    "        objective = Minimize(cvxpynorm(operator,2))\n",
    "        constraints = [cvxpynorm(Yf-operator*Yp,'fro')/cvxpynorm(Yf,'fro')<0.01 ]\n",
    "        prob = Problem(objective, constraints)\n",
    "        result = prob.solve(verbose=True)#(solver=solver_instance);\n",
    "        print(prob.status);\n",
    "        K = operator.value;\n",
    "\n",
    "    return K;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Circuit_Gene_Names = circuit_names;\n",
    "Circuit_Genes = circuit_ids;\n",
    "\n",
    "#for ind in range(0,len(all_genes)):\n",
    "#    gene = all_genes[ind];\n",
    "#    if 'IcaR' in gene or 'PhlF' in gene or 'GFP' in gene or 'pTrc' in gene or 'LacI' in gene or 'AraC' in gene or 'LuxR' in gene:\n",
    "        #print(gene) \n",
    "#        Circuit_Genes.append(ind);\n",
    "\n",
    "circuit_gene_in_indices = [];        \n",
    "for ind in range(0,len(Circuit_Genes)):\n",
    "    circuit_gene = Circuit_Genes[ind];\n",
    "    #print(common_indices)\n",
    "    if circuit_gene in common_indices:\n",
    "        circuit_gene_in_indices.append(circuit_gene);\n",
    "        print(Circuit_Gene_Names[ind] + \" was included\")\n",
    "    if not (circuit_gene in common_indices):\n",
    "        None;\n",
    "        #print(Circuit_Gene_Names[ind])\n",
    "    else:\n",
    "        circuit_gene_in_indices.append(circuit_gene);\n",
    "        \n",
    "\n",
    "circuit_coords_in_K = set();        \n",
    "for this_index in circuit_gene_in_indices:\n",
    "    circuit_coords_in_K.add(common_indices.index(this_index));\n",
    "circuit_coords_in_K = list(circuit_coords_in_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover Open-Loop Host Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-2a5bc0bc6a54>:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if type(lambda_val)== np.float:\n",
      "<ipython-input-25-2a5bc0bc6a54>:23: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if type(lambda_val) == np.float:\n",
      "/usr/local/lib/python3.8/site-packages/cvxpy/expressions/expression.py:550: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/usr/local/lib/python3.8/site-packages/cvxpy/interface/numpy_interface/ndarray_interface.py:47: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if result.dtype in [numpy.complex, numpy.float64]:\n",
      "<ipython-input-25-2a5bc0bc6a54>:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  result = prob.solve(verbose=False,solver=solver_instance,max_iters=np.int(1e7))#,reltol=1e-10,abstol=1e-10);\n",
      "/usr/local/lib/python3.8/site-packages/cvxpy/interface/numpy_interface/sparse_matrix_interface.py:42: DeprecationWarning: `np.complex` is a deprecated alias for the builtin `complex`. To silence this warning, use `complex` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.complex128` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if value.dtype in [np.double, np.complex]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: m less than n, problem likely degenerate\n",
      "[INFO]: Finished executing cvx solver, printing CVXPY problem status\n",
      "optimal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x118609160> (for post_execute):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\", line 119, in flush_figures\n",
      "    return show(True)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\", line 39, in show\n",
      "    display(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/display.py\", line 313, in display\n",
      "    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/formatters.py\", line 180, in format\n",
      "    data = formatter(obj)\n",
      "  File \"<decorator-gen-2>\", line 2, in __call__\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/formatters.py\", line 224, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/formatters.py\", line 341, in __call__\n",
      "    return printer(obj)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/pylabtools.py\", line 248, in <lambda>\n",
      "    png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs))\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/pylabtools.py\", line 132, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/backend_bases.py\", line 2195, in print_figure\n",
      "    bbox_inches = self.figure.get_tightbbox(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/figure.py\", line 2506, in get_tightbbox\n",
      "    bbox = a.get_tightbbox(renderer)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/artist.py\", line 278, in get_tightbbox\n",
      "    bbox = self.get_window_extent(renderer)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/text.py\", line 902, in get_window_extent\n",
      "    bbox, info, descent = self._get_layout(self._renderer)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/text.py\", line 295, in _get_layout\n",
      "    w, h, d = renderer.get_text_width_height_descent(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 237, in get_text_width_height_descent\n",
      "    font = self._get_agg_font(prop)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 273, in _get_agg_font\n",
      "    font = get_font(fname)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/matplotlib/font_manager.py\", line 1414, in get_font\n",
      "    filename = os.path.realpath(filename)\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/posixpath.py\", line 412, in _joinrealpath\n",
      "    if not name or name == curdir:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#%autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['11']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "# Here the data are normalized prior to filtering out noisy genes\n",
    "# probably should normalize after filtering \n",
    "import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list_log_norm[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list_log_norm[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list_log_norm[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list_log_norm[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "\n",
    "\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "all_genes = list(all_genes)\n",
    "lambda_val_vec_p = np.expand_dims(np.std(Yp_data,axis=1),axis=1)\n",
    "lambda_val_vec_f = np.expand_dims(np.std(Yf_data,axis=1),axis=1)\n",
    "lambda_val_vec = np.std(np.hstack( (lambda_val_vec_p,lambda_val_vec_f)),axis=1)\n",
    "this_K = calc_Koopman(Yf_data,Yp_data,flag=2,lambda_val=0.0*lambda_val_vec)\n",
    "\n",
    "gain_K = np.linalg.norm(this_K,ord='fro')\n",
    "gain_K = gain_K/(this_K.shape[0]*this_K.shape[1])\n",
    "gain_K\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(this_K,cmap='RdYlGn',xticklabels=all_gene_labels,yticklabels=all_gene_labels,annot=True,annot_kws={\"size\": 13},fmt='.1f')\n",
    "# sns.heatmap(this_K,cmap='Spectral')\n",
    "sns.set(font_scale=1.4)\n",
    "# hm=sns.heatmap(G,xticklabels=this_xlabels,yticklabels=this_ylabels,cmap='RdYlGn',annot=True)\n",
    "save_results_to = '/Users/aqib/Desktop/UCSB/Research/BCCL/structuredDMD/figures/'\n",
    "# plt.savefig(save_results_to + 'K_host_host.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000005, 1.0000001, 1.0000006, 1.0000002], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(T2_list,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input Lifting and Input-Koopman Dynamics - Arabinose Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StateLinearDictionary = []\n",
    "for elem in range(0,len(common_indices)):\n",
    "    exec('l= lambda x:x[' + repr(elem) + ']')\n",
    "    StateLinearDictionary.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StateLinearDictionary[0](np.random.uniform(0,1,len(common_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# StateLinearDictionary = [lambda x:x[elem] for elem in np.arange(0,len(common_indices),1)];\n",
    "StateLinearDictionary = []\n",
    "for elem in range(0,len(common_indices)):\n",
    "    exec('l= lambda x:x[' + repr(elem) + ']')\n",
    "    StateLinearDictionary.append(l)\n",
    "StateLifting = Lifting(np.arange(1,len(common_indices),1),StateLinearDictionary,len(common_indices))\n",
    "KM = InputKoopmanModel(this_K,StateLifting,None,None)\n",
    "\n",
    "InputQuadraticDictionary = []\n",
    "for elem in np.arange(0,len(common_indices),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']*x[-1]')\n",
    "    InputQuadraticDictionary.append(g);\n",
    "\n",
    "\n",
    "InputQuadraticDictionary = InputQuadraticDictionary+[lambda xu:xu[-1]]; \n",
    "\n",
    "InputLifting = Lifting(np.arange(0,len(InputQuadraticDictionary)),InputQuadraticDictionary,len(InputQuadraticDictionary))\n",
    "\n",
    "\n",
    "#%autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['10']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp = np.zeros((InputLifting.return_dim(),Up_data.shape[1]));\n",
    "for ind in range(0,Up_data.shape[1]):\n",
    "    xu_vec = np.vstack((Yp_data[:,ind].reshape((len(Yp_data[:,ind]),1)),Up_data[:,ind].reshape(len(Up_data[:,ind]),1)))\n",
    "    PsiUp[:,ind] = InputLifting.eval_lifting_array(xu_vec).flatten();\n",
    "\n",
    "PsiUpMaxDelta= np.zeros((InputLifting.return_dim(),Up_data.shape[1])); \n",
    "std_vec = np.vstack((np.expand_dims(np.std(Yp_data,axis=1),1), np.expand_dims(np.std(Up_data,axis=1),1))  )\n",
    "for ind in range(0,Up_data.shape[1]):\n",
    "    xu_vec = np.vstack((Yp_data[:,ind].reshape((len(Yp_data[:,ind]),1)),Up_data[:,ind].reshape(len(Up_data[:,ind]),1)))\n",
    "    xu_vec = xu_vec + std_vec;\n",
    "    PsiUpMaxDelta[:,ind] = InputLifting.eval_lifting_array(xu_vec).flatten();\n",
    "\n",
    "PsiDelta = PsiUpMaxDelta-PsiUp;\n",
    "\n",
    "    \n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "Ki = calc_Input_Koopman(KM.Kol,Yf_data,Yp_data,PsiUp,flag=2,lambda_val=0.0*lambda_val_vec,PsiDelta_Mat = PsiDelta)\n",
    "KM.K_input = Ki;\n",
    "KM.Ki = Ki;\n",
    "\n",
    "KM.Psi_input = InputLifting;\n",
    "KM.Pi = InputLifting;\n",
    "\n",
    "gain_K = np.linalg.norm(Ki,ord='fro')\n",
    "gain_K = gain_K/(Ki.shape[0]*Ki.shape[1])\n",
    "gain_K\n",
    "\n",
    "\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "plt.figure(figsize=(3,10))\n",
    "# sns.set(font_scale=8.0)\n",
    "# this_x_labels = ['['+elem+']' + '' + '[ara]' for elem in all_gene_labels]\n",
    "# this_x_labels = this_x_labels + ['[ara]']\n",
    "# sns.heatmap(Ki,cmap='Spectral',xticklabels=this_x_labels,yticklabels=all_gene_labels)\n",
    "# sns.heatmap(Ki,cmap='Spectral')\n",
    "# plt.figure(figsize=(5,100))\n",
    "sns.heatmap(np.expand_dims(Ki[:,-1],axis=1),cmap='RdYlGn',xticklabels=['L-arabinose'],yticklabels=all_gene_labels,annot=True,annot_kws={\"size\": 18},fmt='.2f')\n",
    "# save_results_to = '/Users/aqib/Desktop/UCSB/Research/BCCL/structuredDMD/figures/'\n",
    "# plt.savefig(save_results_to + 'K_host_arabinose.pdf',bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPTG response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# StateLinearDictionary = [lambda x:x[elem] for elem in np.arange(0,len(common_indices),1)];\n",
    "StateLinearDictionary = []\n",
    "for elem in range(0,len(common_indices)):\n",
    "    exec('l= lambda x:x[' + repr(elem) + ']')\n",
    "    StateLinearDictionary.append(l)\n",
    "StateLifting = Lifting(np.arange(1,len(common_indices),1),StateLinearDictionary,len(common_indices))\n",
    "KM = InputKoopmanModel(this_K,StateLifting,None,None)\n",
    "\n",
    "\n",
    "InputQuadraticDictionary = []\n",
    "for elem in np.arange(0,len(common_indices),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']*x[-1]')\n",
    "    InputQuadraticDictionary.append(g);\n",
    "\n",
    "\n",
    "InputQuadraticDictionary = InputQuadraticDictionary+[lambda xu:xu[-1]]; \n",
    "\n",
    "InputLifting = Lifting(np.arange(0,len(InputQuadraticDictionary)),InputQuadraticDictionary,len(InputQuadraticDictionary))\n",
    "\n",
    "\n",
    "#%autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['01']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp = np.zeros((InputLifting.return_dim(),Up_data.shape[1]));\n",
    "for ind in range(0,Up_data.shape[1]):\n",
    "    xu_vec = np.vstack((Yp_data[:,ind].reshape((len(Yp_data[:,ind]),1)),Up_data[:,ind].reshape(len(Up_data[:,ind]),1)))\n",
    "    PsiUp[:,ind] = InputLifting.eval_lifting_array(xu_vec).flatten();\n",
    "\n",
    "PsiUpMaxDelta= np.zeros((InputLifting.return_dim(),Up_data.shape[1])); \n",
    "std_vec = np.vstack((np.expand_dims(np.std(Yp_data,axis=1),1), np.expand_dims(np.std(Up_data,axis=1),1))  )\n",
    "for ind in range(0,Up_data.shape[1]):\n",
    "    xu_vec = np.vstack((Yp_data[:,ind].reshape((len(Yp_data[:,ind]),1)),Up_data[:,ind].reshape(len(Up_data[:,ind]),1)))\n",
    "    xu_vec = xu_vec + std_vec;\n",
    "    PsiUpMaxDelta[:,ind] = InputLifting.eval_lifting_array(xu_vec).flatten();\n",
    "\n",
    "PsiDelta = PsiUpMaxDelta-PsiUp;\n",
    "\n",
    "    \n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "Ki = calc_Input_Koopman(KM.Kol,Yf_data,Yp_data,PsiUp,flag=2,lambda_val=0.0*lambda_val_vec,PsiDelta_Mat = PsiDelta)\n",
    "KM.K_input = Ki;\n",
    "KM.Ki = Ki;\n",
    "\n",
    "KM.Psi_input = InputLifting;\n",
    "KM.Pi = InputLifting;\n",
    "\n",
    "gain_K = np.linalg.norm(Ki,ord='fro')\n",
    "gain_K = gain_K/(Ki.shape[0]*Ki.shape[1])\n",
    "gain_K\n",
    "\n",
    "# sns.set(font_scale=8.0)\n",
    "# all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "plt.figure(figsize=(3,10))\n",
    "# this_x_labels = ['['+elem+']' + '' + '[IPTG]' for elem in all_gene_labels]\n",
    "# this_x_labels = this_x_labels + ['[IPTG]']\n",
    "# sns.heatmap(Ki,cmap='Spectral',xticklabels=this_x_labels,yticklabels=all_gene_labels)\n",
    "# plt.figure(figsize=(5,100))\n",
    "sns.heatmap(np.expand_dims(Ki[:,-1],axis=1),cmap='RdYlGn',xticklabels=['IPTG'],yticklabels=all_gene_labels,annot=True,annot_kws={\"size\": 18},fmt='.2f')\n",
    "# plt.savefig(save_results_to + 'K_host_iptg.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define PhlF (IPTG) Input Dynamics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "InputLinearDictionary = [None]*len(all_genes)\n",
    "for elem in np.arange(0,len(all_genes),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']')\n",
    "    InputLinearDictionary[elem] = g;\n",
    "     \n",
    "\n",
    "InputLifting = Lifting(np.arange(4098,4136,1),InputLinearDictionary,len(all_genes)-4098)\n",
    "\n",
    "#%autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['01']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "#this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "this_strain_id = 'MG1655_PhlF_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer1.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "#T1_list = T1_list_log;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp_Gate = np.zeros( (InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten();\n",
    "\n",
    "lambda_uamend_val_vec = np.std(PsiUp_Gate,axis=1);\n",
    "PsiUp_Gate_MaxDelta = np.zeros( (InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate_MaxDelta[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten() + lambda_uamend_val_vec;\n",
    "\n",
    "PsiUp_Delta = PsiUp_Gate_MaxDelta-PsiUp_Gate;    \n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "Ki = calc_Append_Input_Koopman(KM.Kol,KM.Ki,Yf_data,Yp_data,PsiUp,PsiUp_Gate,flag=2,lambda_uamend_val=0.001*lambda_uamend_val_vec,PsiUp_Delta_Mat=PsiUp_Delta)\n",
    "KM.append_input(Ki,InputLifting)\n",
    "K_phlf = Ki\n",
    "\n",
    "gain_K = np.linalg.norm(Ki,ord='fro')\n",
    "gain_K = gain_K/(Ki.shape[0]*Ki.shape[1])\n",
    "gain_K\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.set(font_scale=2)\n",
    "# all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.heatmap(Ki,cmap='RdYlGn',xticklabels=Circuit_Gene_Names,yticklabels=all_gene_labels,annot=True,annot_kws={\"size\": 14},fmt='2.0f')\n",
    "plt.yticks(rotation=0);\n",
    "# plt.savefig(save_results_to + 'K_host_iptg_phlf_yfp.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define IcaR (IPTG) Gate Lifting and Input-Dynamics (should actually have been IcaR (L-arabinose) but that condition was not run?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "InputLinearDictionary = [None]*len(all_genes)\n",
    "for elem in np.arange(0,len(all_genes),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']')\n",
    "    InputLinearDictionary[elem] = g;\n",
    "     \n",
    "\n",
    "InputLifting = Lifting(np.arange(4098,4136,1),InputLinearDictionary,len(all_genes)-4098)\n",
    "\n",
    "#%autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['01']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "#this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "this_strain_id = 'MG1655_IcaR_Gate'\n",
    "#this_strain_id = 'MG1655_PhlF_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer1.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "#T1_list = T1_list_log;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp_Gate = np.zeros( (InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten();\n",
    "\n",
    "lambda_uamend_val_vec = np.std(PsiUp_Gate,axis=1);\n",
    "PsiUp_Gate_MaxDelta = np.zeros( (InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate_MaxDelta[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten() + lambda_uamend_val_vec;\n",
    "\n",
    "PsiUp_Delta = PsiUp_Gate_MaxDelta-PsiUp_Gate;    \n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "Ki = calc_Append_Input_Koopman(KM.Kol,KM.Ki,Yf_data,Yp_data,PsiUp,PsiUp_Gate,flag=2,lambda_uamend_val=1*lambda_uamend_val_vec,PsiUp_Delta_Mat=PsiUp_Delta)\n",
    "KM.append_input(Ki,InputLifting)\n",
    "K_icar = Ki\n",
    "\n",
    "\n",
    "gain_K = np.linalg.norm(Ki,ord='fro')\n",
    "gain_K = gain_K/(Ki.shape[0]*Ki.shape[1])\n",
    "gain_K\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.set(font_scale=2)\n",
    "# all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.heatmap(Ki,cmap='RdYlGn',xticklabels=Circuit_Gene_Names,yticklabels=all_gene_labels,annot=True,annot_kws={\"size\": 14},fmt='2.0f')\n",
    "plt.yticks(rotation=0);\n",
    "# plt.savefig(save_results_to + 'K_host_ara_icar_yfp.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many nonzero terms in Circuit_IcaR\n",
    "for ind in range(0,len(circuit_names)):\n",
    "    if circuit_names[ind] == 'Circuit_IcaR':\n",
    "        icar_ind = ind\n",
    "\n",
    "K_icar_count = K_icar[:,icar_ind]\n",
    "count_icar = 0\n",
    "for ind in range(0,len(K_icar_count)):\n",
    "    if K_icar_count[ind] > 0:\n",
    "        count_icar = count_icar + 1\n",
    "\n",
    "# how many nonzero terms in Circuit_PhlF\n",
    "for ind in range(0,len(circuit_names)):\n",
    "    if circuit_names[ind] == 'Circuit_PhlF':\n",
    "        phlf_ind = ind\n",
    "\n",
    "K_phlf_count = K_phlf[:,phlf_ind]\n",
    "count_phlf = 0\n",
    "for ind in range(0,len(K_phlf_count)):\n",
    "    if K_phlf_count[ind] > 0:\n",
    "        count_phlf = count_phlf + 1\n",
    "        \n",
    "# count_phlf\n",
    "count_icar\n",
    "# len(K_icar_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NAND Circuit Gate Lifting and Input-Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "InputLinearDictionary = [None]*len(all_genes)\n",
    "for elem in np.arange(0,len(all_genes),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']')\n",
    "    InputLinearDictionary[elem] = g;\n",
    "     \n",
    "\n",
    "InputLifting = Lifting(np.arange(4098,4136,1),InputLinearDictionary,len(all_genes)-4098)\n",
    "\n",
    "#%autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['10']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "#this_strain_id = 'MG1655_WT'\n",
    "this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "#this_strain_id = 'MG1655_PhlF_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer1.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "#T1_list = T1_list_log;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp_Gate = np.zeros( (InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten();\n",
    "\n",
    "lambda_uamend_val_vec = np.std(PsiUp_Gate,axis=1);\n",
    "PsiUp_Gate_MaxDelta = np.zeros( (InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate_MaxDelta[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten() + lambda_uamend_val_vec;\n",
    "\n",
    "PsiUp_Delta = PsiUp_Gate_MaxDelta-PsiUp_Gate;    \n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "Ki = calc_Append_Input_Koopman(KM.Kol,KM.Ki,Yf_data,Yp_data,PsiUp,PsiUp_Gate,flag=2,lambda_uamend_val=0*lambda_uamend_val_vec,PsiUp_Delta_Mat=PsiUp_Delta)\n",
    "KM.append_input(Ki,InputLifting)\n",
    "\n",
    "gain_K = np.linalg.norm(Ki,ord='fro')\n",
    "gain_K = gain_K/(Ki.shape[0]*Ki.shape[1])\n",
    "gain_K\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.set(font_scale=2)\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.heatmap(Ki,cmap='RdYlGn',xticklabels=Circuit_Gene_Names,yticklabels=all_gene_labels,annot=True,annot_kws={\"size\": 14},fmt='2.0f')\n",
    "# save_results_to = '/Users/aqib/Desktop/UCSB/Research/BCCL/structuredDMD/figures/'\n",
    "# plt.savefig(save_results_to + 'K_host_arabinose_iptg_icar_phlf_yfp_test.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.set(font_scale=2)\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.heatmap(Ki[13:,:],cmap='RdYlGn',xticklabels=Circuit_Gene_Names,yticklabels=circuit_names,annot=True,annot_kws={\"size\": 14},fmt='2.0f')\n",
    "save_results_to = '/Users/aqib/Desktop/'\n",
    "# plt.savefig(save_results_to + 'PhlF_impact.png',bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ki.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
