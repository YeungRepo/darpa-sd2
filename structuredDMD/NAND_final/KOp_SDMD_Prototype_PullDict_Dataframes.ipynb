{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; \n",
    "import matplotlib.pyplot as plt; \n",
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "JU_frame = pd.read_csv('NAND_Chassis_RNAseq_preCAD_TPM.tsv',sep='\\t');                        \n",
    "# print(JU_frame.columns)                       \n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_column_names = JU_frame.columns;\n",
    "\n",
    "# For parsing TACC columns \n",
    "new_column_names = [None]*len(all_column_names);\n",
    "new_column_names[0] = all_column_names[0];\n",
    "for col_ind in range(1,len(all_column_names)):\n",
    "    column_name = str(all_column_names[col_ind]);\n",
    "#     print(column_name)\n",
    "    this_id = column_name.split('.')[-1];\n",
    "#     print(this_id)\n",
    "    new_column_names[col_ind] = this_id;\n",
    "    \n",
    "clear_JU_frame = pd.DataFrame(JU_frame);\n",
    "clear_JU_frame.columns = new_column_names; # what is clear_JU_frame here used for, it's overwritten soon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Synthetic_Genes = clear_JU_frame.gene_id[4098:]\n",
    "# print(Synthetic_Genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dict_file = open('dict_files.pickle','rb')\n",
    "dict_list = pickle.load(dict_file);\n",
    "strain_to_ids_dict = dict_list[0];\n",
    "cond_dict = dict_list[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_JU_frame = pd.DataFrame.from_csv('Floated_Reordered_ReadCountMatrix_preCAD_Normal_TPM.csv')\n",
    "# clear_JU_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_strains = strain_to_ids_dict.keys();\n",
    "master_dict = dict();\n",
    "\n",
    "for this_strain_id in all_strains:\n",
    "    wt_ids = list(set(strain_to_ids_dict[this_strain_id]));    \n",
    "    data_by_cond_dict = dict();\n",
    "    for wt_id in wt_ids:\n",
    "        cond_num = cond_dict[wt_id];\n",
    "        if cond_num[0] > 0.0:\n",
    "            ara_state = '1';\n",
    "        else:\n",
    "            ara_state = '0';\n",
    "        if cond_num[1] > 0.0:\n",
    "            iptg_state = '1';\n",
    "        else:\n",
    "            iptg_state = '0';\n",
    "        \n",
    "        temperature = repr(int(cond_num[2]));\n",
    "        timepoint = repr(int(cond_num[3]));\n",
    "        replicate_num = repr(int(cond_num[4]));\n",
    "        \n",
    "        cond_key = ara_state + iptg_state + temperature + timepoint + replicate_num;\n",
    "        \n",
    "        if wt_id in clear_JU_frame.columns:\n",
    "            data_for_condition = clear_JU_frame[wt_id].as_matrix();\n",
    "            for ind in range(0,data_for_condition.shape[0]):\n",
    "                data_for_condition = data_for_condition;    \n",
    "\n",
    "            if this_strain_id in master_dict.keys():\n",
    "                if cond_key in master_dict[this_strain_id].keys():\n",
    "                    master_dict[this_strain_id][cond_key].append(data_for_condition);    \n",
    "                else:    \n",
    "                    master_dict[this_strain_id][cond_key] = [data_for_condition];\n",
    "\n",
    "            else:\n",
    "                master_dict[this_strain_id] = dict(); \n",
    "                if cond_key in master_dict[this_strain_id].keys():\n",
    "                    master_dict[this_strain_id][cond_key].append(data_for_condition);    \n",
    "                else:    \n",
    "                    master_dict[this_strain_id][cond_key] = [data_for_condition];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepair_list = [];\n",
    "for ind_cond in ['00']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_genes = clear_JU_frame['gene_id'];\n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "\n",
    "    \n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "\n",
    "# %autoreload\n",
    "viz_this_set = True; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['01']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);            \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer1 = MinMaxScaler(feature_range=(-1,1)).fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = MinMaxScaler(feature_range=(-1,1)).fit(T2_list_raw)\n",
    "T2_list =  transformer1.transform(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "# import sklearn;\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# transformer1 = Normalizer().fit(T1_list_raw)\n",
    "# T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "# transformer2 = Normalizer().fit(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "#T1_list = T1_list_log;\n",
    "#T2_list = T2_list_log;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Genes with Noise Higher Than Signal, Filtering (Fast Timescale) Steady-State Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for sub_rep in [[0,1,2,3]]:\n",
    "for sub_rep in [[0,1,2],[0,1,3],[1,2,3],[0,2,3],[0,1,2,3]]:\n",
    "#     plt.figure(figsize=(10,10))\n",
    "    \n",
    "    mu_t1 = np.mean(T1_list[sub_rep][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[sub_rep][:],axis=0);\n",
    "    \n",
    "    mu_t2 = np.mean(T2_list[sub_rep][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[sub_rep][:],axis=0);\n",
    "    cv1 = mu_t1 - mu_t1;\n",
    "    cv2 = mu_t2 - mu_t2;\n",
    "    low_cv_indices = [];\n",
    "    for k in range(0,len(mu_t1)):\n",
    "        good_cv = True;\n",
    "        if mu_t1[k] > 0.0:\n",
    "            cv1[k] = s_t1[k]/mu_t1[k];\n",
    "            if cv1[k] > 0.1:\n",
    "                good_cv = False;\n",
    "        else:\n",
    "            good_cv = False;\n",
    "        if mu_t2[k] > 0.0:\n",
    "            cv2[k] = s_t2[k]/mu_t2[k];\n",
    "            if cv2[k] > 0.1:\n",
    "                good_cv = False;\n",
    "        else:\n",
    "            good_cv = False;\n",
    "            \n",
    "        if mu_t1[k] > 0.0 and mu_t2[k] > 0.0:\n",
    "            if np.abs(mu_t1[k]/mu_t2[k] - 1.0) < 0.3:\n",
    "                good_cv = False;\n",
    "        \n",
    "        if good_cv:\n",
    "            low_cv_indices.append(k);\n",
    "    #print(all_genes[low_cv_indices]);\n",
    "    \n",
    "    #plt.scatter((mu_t1),cv1,alpha=0.1);\n",
    "    #plt.scatter((mu_t2),cv2,alpha=0.1);\n",
    "\n",
    "    \n",
    "#    plt.scatter(np.arange(0,T1_list.shape[1],1),cv1,alpha=0.1);\n",
    "#    plt.scatter(np.arange(0,T2_list.shape[1],1),cv2,alpha=0.1);\n",
    "    #ax = plt.gca();\n",
    "    #ax.spines['right'].set_visible(False)\n",
    "    #ax.spines['top'].set_visible(False)\n",
    "    #sub_rep_str = [str(elem) for elem in sub_rep]\n",
    "    #plt.legend(['Samples '+','.join(sub_rep_str)+' @ 5 hr','Samples ' + ','.join(sub_rep_str)+' @ 18 hr'] )\n",
    "    #plt.ylim([-.05,0.6])\n",
    "    #plt.ylabel('Coefficient of Variation (s/µ)')\n",
    "    #plt.xlabel('Mean of FPKM (log)')\n",
    "#plt.errorbar(np.arange(0,T2_list.shape[1],1),np.std(T2_list,axis=0)/np.mean(T2_list,axis=0) );\n",
    "#plt.errorbar(np.arange(0,T2_list.shape[1],1), np.mean(T2_list,axis=0), yerr=np.std(T2_list,axis=0));\n",
    "#plt.ylim([0,1e4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"# of genes with low FPKM CV: \" + repr(len(low_cv_indices)))\n",
    "#print(\"# of genes with low FPKM CV: \" + repr(len(all_genes)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirtyseven_low_cv_indices = low_cv_indices;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lac_indices = [];\n",
    "for ind in range(0,len(all_genes)):\n",
    "    if 'lac' in str(all_genes[ind]):#.lower():\n",
    "        lac_indices.append(ind)\n",
    "\n",
    "ara_indices = [];\n",
    "for ind in range(0,len(all_genes)):\n",
    "    if 'ara' in str(all_genes[ind]):#.lower():\n",
    "        ara_indices.append(ind)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in ara_indices:\n",
    "    print(all_genes[ind])\n",
    "    \n",
    "for ind in lac_indices:\n",
    "    print(all_genes[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common_indices = list(set(thirtyseven_low_cv_indices).intersection( set(thirty_low_cv_indices) ));\n",
    "# common_indices = thirtyseven_low_cv_indices\n",
    "common_indices = ara_indices+lac_indices;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_ids = list(np.arange(4098,len(all_genes),1))#list(np.arange(0,13,1))\n",
    "circuit_names = list(all_genes)[circuit_ids[0]:(circuit_ids[-1]+1)]\n",
    "# print(circuit_names)\n",
    "# len(circuit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "# for col_ind in [0,2,3]:\n",
    "#     plt.bar(np.arange(1,len(circuit_ids),1),T2_list.T[circuit_ids[0]:circuit_ids[-1],col_ind],alpha=0.25)\n",
    "    \n",
    "# ax = plt.gca()\n",
    "# ax.set_xticks(np.arange(1,len(circuit_ids),1))\n",
    "# ax.set_xticklabels(circuit_names,rotation=-90,fontsize=14)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# plt.legend(['Replicate 0','Replicate 2','Replicate 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]] = T2_list.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for ind in range(0,Yp_data.shape[1]):\n",
    "#     plt.figure()\n",
    "#     plt.scatter(Yp_data[:,ind],Yf_data[:,ind])\n",
    "#     plt.figure()\n",
    "#     plt.scatter(Yp_data[:,ind],Yp_data[:,ind-1],color='r')\n",
    "#     plt.figure()\n",
    "#     plt.scatter(Yf_data[:,ind],Yf_data[:,ind-1],color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user cvxopt\n",
    "\n",
    "from cvxopt import matrix, solvers\n",
    "!pip install --user cvxpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxpy import Minimize\n",
    "from cvxpy import Minimize, Problem, Variable,norm1,installed_solvers,lambda_max;\n",
    "from cvxpy import norm as cvxpynorm;\n",
    "import cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autoreload\n",
    "class Lifting:\n",
    "#     import numpy as np\n",
    "    \n",
    "    def __init__(self,this_index_of_used_functions,this_function_dictionary,this_num_input_vars):\n",
    "        self.function_dictionary = list(this_function_dictionary);\n",
    "        self.indices_of_used_functions = list(this_index_of_used_functions);\n",
    "        self.num_input_vars = np.int(this_num_input_vars);\n",
    "        \n",
    "            \n",
    "#     def eval_lifting_list(self,input_var):\n",
    "#         import numpy as np;\n",
    "#         evaluated_lifting = -1.0;\n",
    "#         #if not (len(input_var)== self.num_input_vars):\n",
    "#         #    print(\"Error: input var supplied does not match target input var size:\" + repr (self.num_input_vars));\n",
    "#         #    import numpy as np;\n",
    "#         #    return evaluated_lifting;\n",
    "#         #else:\n",
    "#         evaluated_lifting = [];\n",
    "#         for dict_index in self.indices_of_used_functions:\n",
    "#             this_dictionary_function = self.function_dictionary[dict_index];\n",
    "#             evaluated_lifting.append(this_dictionary_function(input_var))\n",
    "\n",
    "#         return evaluated_lifting;\n",
    "    \n",
    "    \n",
    "    def eval_lifting_array(self,input_var):\n",
    "        import numpy as np;\n",
    "        evaluated_lifting = -1.0\n",
    "        #if not (len(input_var)== self.num_input_vars):\n",
    "        #    print(\"Error: input var supplied does not match target input var size:\" + repr (self.num_input_vars));\n",
    "        #    import numpy as np;\n",
    "        #    return evaluated_lifting;\n",
    "\n",
    "        evaluated_lifting = [];\n",
    "        for dict_index in self.indices_of_used_functions:\n",
    "            \n",
    "            this_dictionary_function = self.function_dictionary[dict_index];\n",
    "            evaluated_lifting.append(this_dictionary_function(input_var))\n",
    "        \n",
    "        return np.asarray(evaluated_lifting).reshape((len(evaluated_lifting),1));\n",
    "\n",
    "    def append_lifting_terms(self,new_index_of_used_functions,new_function_dictionary,new_num_input_vars):\n",
    "        \n",
    "        try:\n",
    "            if len(new_index_of_used_functions) > len(new_function_dictionary):\n",
    "                raise Exception('number of indices of used functions should not exceed length of new function dictionary');\n",
    "            self.indices_of_used_functions = self.indices_of_used_functions + list(new_index_of_used_functions + len(self.function_dictionary)); \n",
    "            self.num_input_vars = self.num_input_vars + new_num_input_vars;\n",
    "            self.function_dictionary = self.function_dictionary + list(new_function_dictionary);\n",
    "            return self;\n",
    "        except (Exception):\n",
    "            return -1.0;\n",
    "        \n",
    "#     def lifting_dim(self):\n",
    "#         return len(self.indices_of_used_functions);\n",
    "    \n",
    "    def return_dim(self):\n",
    "        return len(self.indices_of_used_functions);\n",
    "    \n",
    "    def print_Koopman_string_meme(self):\n",
    "        print('Bro, are you even ' + repr(self)[10:] )\n",
    "        \n",
    "        \n",
    "    # to do for AH and NB, what other abstract properties should a lifting object have? \n",
    "# %autoreload  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputKoopmanModel:\n",
    "    def __init__(self,this_K_open_loop,this_state_lifting,this_K_input,this_input_lifting):\n",
    "        self.K_open_loop = np.asarray(this_K_open_loop,dtype=np.float32)\n",
    "        self.K_input =  np.asarray(this_K_input,dtype=np.float32)\n",
    "        self.Psi_open_loop = this_state_lifting\n",
    "        self.Psi_input = this_input_lifting\n",
    "        \n",
    "        self.Kol = self.K_open_loop\n",
    "        self.Ki = self.K_input\n",
    "        self.Pol = self.Psi_open_loop\n",
    "        self.Pi = self.Psi_input\n",
    "        \n",
    "    def append_input(self,new_K_input,new_input_lifting):\n",
    "        try:\n",
    "            self.K_input = np.hstack((self.K_input,np.asarray(new_K_input,dtype=np.float32)));\n",
    "        except:\n",
    "            print(self.K_input.shape)\n",
    "            print(new_K_input.shape)\n",
    "        niuf= new_input_lifting.indices_of_used_functions;\n",
    "        niv = new_input_lifting.num_input_vars; \n",
    "        nfd = new_input_lifting.function_dictionary;    \n",
    "        self.Psi_input.append_lifting_terms(niuf,nfd,niv);\n",
    "        \n",
    "    def eval_diff(self,state_vec,input_vec):\n",
    "        return np.dot(self.Kol,self.Pol.eval_lifting_array(state_vec)) + np.dot(self.Ki,self.Pi.eval_lifting_array(input_vec));\n",
    "        \n",
    "    def print_Koopman_string_meme(self):\n",
    "        print('Bro, do you even lift?');\n",
    "        \n",
    "    \n",
    "def calc_Input_Koopman(Kol,Yf,Yp,Up,flag=1,lambda_val=0.0):\n",
    "    solver_instance = cvxpy.SCS;\n",
    "    Ki = None;\n",
    "    if flag==1: # moore penrose inverse, plain ol' least squares input-Koopman\n",
    "        #Yp_inv = np.dot(np.transpose(Yp_final), np.linalg.inv( np.dot(Yp_final,np.transpose(Yp_final)) )   );\n",
    "        Yfprime = Yf-np.dot(Kol,Yp)\n",
    "        Up_inv = np.linalg.pinv(Up);\n",
    "        Ki = np.dot(Yfprime,Up_inv);\n",
    "        \n",
    "\n",
    "    if flag ==2: # cvx optimization approach - L2 + L1 lasso \n",
    "        norm1_term = 0.0;\n",
    "        all_col_handles = [None]*Up.shape[0]\n",
    "        for i in range(0,Up.shape[0]):\n",
    "            #print(Yf.shape[0])\n",
    "            all_col_handles[i] = Variable(shape=(Yf.shape[0],1)) ;#Variable(shape=(Yf.shape[0],1) );\n",
    "        #    if norm1_term < cvxpy.norm(all_col_handles[i],p=1):\n",
    "        #        norm1_term = cvxpy.norm(all_col_handles[i],p=1);\n",
    "            #norm1_term =  cvxpy.max(cvxpy.hstack( [norm1_term,cvxpy.norm(all_col_handles[i],p=1) ])  );\n",
    "        operator = cvxpy.hstack(all_col_handles);\n",
    "        norm1_term =cvxpy.norm( operator,p=1);\n",
    "        #operator = all_col_handles[0];\n",
    "        #for i in range(1,Yf.shape[0]):\n",
    "        #    operator = cvxpy.hstack([operator,all_col_handles[i]]);\n",
    "        #operator.\n",
    "        #print(\"[INFO]: CVXPY Koopman operator variable: \" +repr(operator.shape));\n",
    "        #print(repr(operator));\n",
    "        #print(\"[INFO]: Yf.shape in calc_Koopman: \" + repr(Yf.shape));\n",
    "        #print(\"[INFO]: Yp.shape in calc_Koopman: \" + repr(Yp.shape));\n",
    "        Yfprime = Yf-np.dot(Kol,Yp)\n",
    "        norm2_fit_term = cvxpy.norm(cvxpy.norm(Yfprime-operator*Up,p=2,axis=0),p=2);\n",
    "        objective = Minimize(norm2_fit_term + lambda_val*norm1_term)\n",
    "        constraints = [];\n",
    "        prob = Problem(objective,constraints);\n",
    "        result = prob.solve(verbose=True,solver=solver_instance,max_iters=np.int(1e7))#,reltol=1e-10,abstol=1e-10);\n",
    "        print(\"[INFO]: Finished executing cvx solver, printing CVXPY problem status\")\n",
    "        print(prob.status);\n",
    "        Ki = operator.value;\n",
    "    return Ki;\n",
    "        \n",
    "def calc_Append_Input_Koopman(Kol,Ki,Yf,Yp,Up,Uamend,flag=1,lambda_val=0.0):\n",
    "    solver_instance = cvxpy.SCS;\n",
    "    Kamend = None;\n",
    "    if flag==1: # moore penrose inverse, plain ol' least squares input-Koopman\n",
    "        #Yp_inv = np.dot(np.transpose(Yp_final), np.linalg.inv( np.dot(Yp_final,np.transpose(Yp_final)) )   );\n",
    "        Yfprime = Yf-np.dot(Kol,Yp)-np.dot(Ki,Up);\n",
    "        Ua_inv = np.linalg.pinv(Uamend);\n",
    "        Kamend = np.dot(Yfprime,Ua_inv);\n",
    "        \n",
    "\n",
    "    if flag ==2: # cvx optimization approach - L2 + L1 lasso \n",
    "        norm1_term = 0.0;\n",
    "        all_col_handles = [None]*Uamend.shape[0]\n",
    "        for i in range(0,Uamend.shape[0]):            \n",
    "            all_col_handles[i] = Variable(shape=(Yf.shape[0],1)) ;#Variable(shape=(Yf.shape[0],1) );\n",
    "        #    if norm1_term < cvxpy.norm(all_col_handles[i],p=1):\n",
    "        #        norm1_term = cvxpy.norm(all_col_handles[i],p=1);\n",
    "            #norm1_term =  cvxpy.max(cvxpy.hstack( [norm1_term,cvxpy.norm(all_col_handles[i],p=1) ])  );\n",
    "        operator = cvxpy.hstack(all_col_handles);\n",
    "        norm1_term =cvxpy.norm(operator,p=1);\n",
    "        #operator = all_col_handles[0];\n",
    "        #for i in range(1,Yf.shape[0]):\n",
    "        #    operator = cvxpy.hstack([operator,all_col_handles[i]]);\n",
    "        #operator.\n",
    "        #print(\"[INFO]: CVXPY Koopman operator variable: \" +repr(operator.shape));\n",
    "        #print(repr(operator));\n",
    "        #print(\"[INFO]: Yf.shape in calc_Koopman: \" + repr(Yf.shape));\n",
    "        #print(\"[INFO]: Yp.shape in calc_Koopman: \" + repr(Yp.shape));\n",
    "        Yfprime = Yf- np.dot(Kol,Yp)-np.dot(Ki,Up)\n",
    "        norm2_fit_term = cvxpy.norm(cvxpy.norm(Yfprime-operator*Uamend,p=2,axis=0),p=2);\n",
    "        objective = Minimize(norm2_fit_term + lambda_val*norm1_term)\n",
    "        constraints = [];\n",
    "        prob = Problem(objective,constraints);\n",
    "        result = prob.solve(verbose=True,solver=solver_instance,max_iters=np.int(1e7))#,reltol=1e-10,abstol=1e-10);\n",
    "        print(\"[INFO]: Finished executing cvx solver, printing CVXPY problem status\")\n",
    "        print(prob.status);\n",
    "        Kamend = operator.value;\n",
    "    return Kamend;        \n",
    "\n",
    "def train_Append_Input_Koopman(Xf,Xp,unl_Up,unl_UAmend,this_InputKoopmanModel,AmendLifting,num_rawstates,num_rawinputs,num_rawamendinputs,num_snapshots):\n",
    "    if Xf.shape[1] == num_rawstates:\n",
    "        Xf = Xf.T;\n",
    "    if Xp.shape[1] ==num_rawstates:\n",
    "        Xp = Xp.T; \n",
    "    if unl_Up.shape[1] == num_rawinputs:\n",
    "        unl_Up = unl_Up.T; \n",
    "    if unl_UAmend.shape[1] == num_rawamendinputs:\n",
    "        unl_UAmend = unl_UAmend.T;\n",
    "        \n",
    "    PsiXf = np.zeros(this_InputKoopmanModel.Pol.return_dim(),Xf.shape[1]);\n",
    "    for ind in range(0,Xf.shape[1]):\n",
    "        PsiXf[:,ind] = this_InputKoopmanModel.Pol.eval_lifting_array(Xf[:,ind]);\n",
    "    \n",
    "    PsiXp = np.zeros(this_InputKoopmanModel.Pol.return_dim(),Xp.shape[1]);\n",
    "    for ind in range(0,Xp.shape[1]):\n",
    "        PsiXp[:,ind] = this_InputKoopmanModel.Pol.eval_lifting_array(Xp[:,ind]);\n",
    "    \n",
    "    PsiUp = np.zeros(this_InputKoopmanModel.Pi.return_dim(),unl_Up.shape[1]);\n",
    "    for ind in range(0,unl_Up.shape[1]):\n",
    "        PsiUp[:,ind] = this_InputKoopmanModel.Pi.eval_lifting_array(unl_Up[:,ind]);\n",
    "    \n",
    "    PsiAUp = np.zeros(AmendLifting.return_dim(),unl_UAmend.shape[1]);\n",
    "    for ind in range(0,unl_UAmend.shape[1]):\n",
    "        PsiAUp[:,ind] = AmendLifting.eval_lifting_array(unl_UAmend[:,ind]);\n",
    "    \n",
    "    this_Kol = this_InputKoopmanModel.Kol;\n",
    "    this_Ki = this_InputKoopmanModel.Ki;\n",
    "    calc_Append_Input_Koopman(this_Kol,this_Ki,PsiXf,PsiXp,PsiUp,PsiAUp,flag=1,lambda_val=0.0)\n",
    "    \n",
    "# %autoreload        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Koopman(Yf,Yp,flag=1,lambda_val=0.0):\n",
    "    #solver_instance = cvxpy.CVXOPT;\n",
    "    solver_instance = cvxpy.SCS;\n",
    "    if flag==1: # moore penrose inverse, plain ol' least squares Koopman\n",
    "        #Yp_inv = np.dot(np.transpose(Yp_final), np.linalg.inv( np.dot(Yp_final,np.transpose(Yp_final)) )   );\n",
    "        Yp_inv = np.linalg.pinv(Yp);\n",
    "        K = np.dot(Yf,Yp_inv);\n",
    "        \n",
    "\n",
    "    if flag ==2: # cvx optimization approach - L2 + L1 lasso \n",
    "        norm1_term = 0.0;\n",
    "        all_col_handles = [None]*Yf.shape[0]\n",
    "        for i in range(0,Yf.shape[0]):            \n",
    "            all_col_handles[i] = Variable(shape=(Yf.shape[0],1)) ;#Variable(shape=(Yf.shape[0],1) );\n",
    "        #    if norm1_term < cvxpy.norm(all_col_handles[i],p=1):\n",
    "        #        norm1_term = cvxpy.norm(all_col_handles[i],p=1);\n",
    "            #norm1_term =  cvxpy.max(cvxpy.hstack( [norm1_term,cvxpy.norm(all_col_handles[i],p=1) ])  );\n",
    "        operator = cvxpy.hstack(all_col_handles);\n",
    "        norm1_term =cvxpy.norm( operator,p=1);\n",
    "        #operator = all_col_handles[0];\n",
    "        #for i in range(1,Yf.shape[0]):\n",
    "        #    operator = cvxpy.hstack([operator,all_col_handles[i]]);\n",
    "        #operator.\n",
    "        #print(\"[INFO]: CVXPY Koopman operator variable: \" +repr(operator.shape));\n",
    "        #print(repr(operator));\n",
    "        #print(\"[INFO]: Yf.shape in calc_Koopman: \" + repr(Yf.shape));\n",
    "        #print(\"[INFO]: Yp.shape in calc_Koopman: \" + repr(Yp.shape));\n",
    "        norm2_fit_term = cvxpy.norm(cvxpy.norm(Yf-operator*Yp,p=2,axis=0),p=2);\n",
    "        objective = Minimize(norm2_fit_term + lambda_val*norm1_term)\n",
    "        constraints = [];\n",
    "        prob = Problem(objective,constraints);\n",
    "        result = prob.solve(verbose=True,solver=solver_instance,max_iters=np.int(1e7))#,reltol=1e-10,abstol=1e-10);\n",
    "        print(\"[INFO]: Finished executing cvx solver, printing CVXPY problem status\")\n",
    "        print(prob.status);\n",
    "        K = operator.value;\n",
    "\n",
    "    if flag ==3:\n",
    "        operator = Variable((Yf.shape[0],Yf.shape[0]))\n",
    "        objective = Minimize(cvxpynorm(operator,2))\n",
    "        constraints = [cvxpynorm(Yf-operator*Yp,'fro')/cvxpynorm(Yf,'fro')<0.01 ]\n",
    "        prob = Problem(objective, constraints)\n",
    "        result = prob.solve(verbose=True)#(solver=solver_instance);\n",
    "        print(prob.status);\n",
    "        K = operator.value;\n",
    "\n",
    "    return K;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Circuit_Gene_Names = circuit_names;\n",
    "Circuit_Genes = circuit_ids;\n",
    "\n",
    "#for ind in range(0,len(all_genes)):\n",
    "#    gene = all_genes[ind];\n",
    "#    if 'IcaR' in gene or 'PhlF' in gene or 'GFP' in gene or 'pTrc' in gene or 'LacI' in gene or 'AraC' in gene or 'LuxR' in gene:\n",
    "        #print(gene) \n",
    "#        Circuit_Genes.append(ind);\n",
    "\n",
    "circuit_gene_in_indices = [];        \n",
    "for ind in range(0,len(Circuit_Genes)):\n",
    "    circuit_gene = Circuit_Genes[ind];\n",
    "    #print(common_indices)\n",
    "    if circuit_gene in common_indices:\n",
    "        circuit_gene_in_indices.append(circuit_gene);\n",
    "        print(Circuit_Gene_Names[ind] + \" was included\")\n",
    "    if not (circuit_gene in common_indices):\n",
    "        None;\n",
    "        #print(Circuit_Gene_Names[ind])\n",
    "    else:\n",
    "        circuit_gene_in_indices.append(circuit_gene);\n",
    "        \n",
    "\n",
    "circuit_coords_in_K = set();        \n",
    "for this_index in circuit_gene_in_indices:\n",
    "    circuit_coords_in_K.add(common_indices.index(this_index));\n",
    "circuit_coords_in_K = list(circuit_coords_in_K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover Open-Loop Host Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %autoreload # this works on Python 2\n",
    "viz_this_set = True; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['00']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# transformer1 = MinMaxScaler(feature_range=(-1,1)).fit(T1_list_raw)\n",
    "# T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "# transformer2 = MinMaxScaler(feature_range=(-1,1)).fit(T2_list_raw)\n",
    "# T2_list =  transformer1.transform(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer2.transform(T2_list_raw)\n",
    "# T2_list = transformer1.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2] \n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list_log_norm[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list_log_norm[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list_log_norm[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list_log_norm[low_cv_reps][:],axis=0);\n",
    "    \n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "#     plt.ylim([-100.0,100.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "#     plt.ylim([-100.0,100.0])\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]] = T2_list_log_norm.T[common_indices,col_ind];\n",
    "    \n",
    "all_genes = list(all_genes)\n",
    "this_K = calc_Koopman(Yf_data,Yp_data,flag=2,lambda_val=0.001)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(5,5))\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.set(font_scale=1.0)\n",
    "sns.heatmap(this_K,cmap='Spectral',xticklabels=all_gene_labels,yticklabels=all_gene_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define State and Input Lifting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StateLinearDictionary = [lambda x:x[elem] for elem in np.arange(0,len(common_indices),1)];\n",
    "StateLifting = Lifting(np.arange(1,len(common_indices)),StateLinearDictionary,len(common_indices))\n",
    "KM = InputKoopmanModel(this_K,StateLifting,None,None) # Koopman Model\n",
    "\n",
    "InputQuadraticDictionary = []\n",
    "for elem in np.arange(0,len(common_indices),1):\n",
    "    exec('g = lambda x:x[' + repr(elem) + ']*x[-1]')\n",
    "    InputQuadraticDictionary.append(g);\n",
    "\n",
    "InputQuadraticDictionary = InputQuadraticDictionary + [lambda xu:xu[-1]]; \n",
    "InputLifting = Lifting(np.arange(0,len(InputQuadraticDictionary)),InputQuadraticDictionary,len(InputQuadraticDictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input-Koopman Dynamics - Arabinose Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['10']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# transformer1 = MinMaxScaler(feature_range=(-1,1)).fit(T1_list_raw)\n",
    "# T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "# transformer2 = MinMaxScaler(feature_range=(-1,1)).fit(T2_list_raw)\n",
    "# T2_list =  transformer1.transform(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "# import sklearn\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp = np.zeros( (InputLifting.return_dim(),Up_data.shape[1]));\n",
    "for ind in range(0,Up_data.shape[1]):\n",
    "    xu_vec = np.vstack((Yp_data[:,ind].reshape((len(Yp_data[:,ind]),1)),Up_data[:,ind].reshape(len(Up_data[:,ind]),1)))\n",
    "    PsiUp[:,ind] = InputLifting.eval_lifting_array(xu_vec).flatten();\n",
    "\n",
    "\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "Ki = calc_Input_Koopman(KM.Kol,Yf_data,Yp_data,PsiUp,flag=2,lambda_val=0.001)\n",
    "KM.K_input = Ki;\n",
    "KM.Ki = Ki;\n",
    "\n",
    "KM.Psi_input = InputLifting;\n",
    "KM.Pi = InputLifting;\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(1,5))\n",
    "sns.set(font_scale=1.0)\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.heatmap(Ki[:,Ki.shape[1]-1].reshape(-1,1),cmap='Spectral',xticklabels=['ara'],yticklabels=all_gene_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define PhlF (ara) Input Dynamics (no such condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "InputLinearDictionary = [None]*len(all_genes)\n",
    "for elem in np.arange(0,len(all_genes),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']')\n",
    "    InputLinearDictionary[elem] = g;\n",
    "     \n",
    "InputLifting = Lifting(np.arange(4098,4136,1),InputLinearDictionary,len(all_genes)-4098)\n",
    "\n",
    "# %autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['10']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "#this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "#this_strain_id = 'MG1655_IcaR_Gate'\n",
    "this_strain_id = 'MG1655_PhlF_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# transformer1 = MinMaxScaler(feature_range=(-1,1)).fit(T1_list_raw)\n",
    "# T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "# transformer2 = MinMaxScaler(feature_range=(-1,1)).fit(T2_list_raw)\n",
    "# T2_list =  transformer1.transform(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "# import sklearn;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "transformer1 = Normalizer().fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = Normalizer().fit(T2_list_raw)\n",
    "T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "#T1_list = T1_list_log;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp_Gate = np.zeros((InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten();\n",
    "\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "    \n",
    "Ki = calc_Append_Input_Koopman(KM.Kol,KM.Ki,Yf_data,Yp_data,PsiUp,PsiUp_Gate,flag=2,lambda_val=0.001)\n",
    "\n",
    "KM.append_input(Ki,InputLifting)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.set(font_scale=1.0)\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.heatmap(Ki,cmap='Spectral',xticklabels=Circuit_Gene_Names,yticklabels=all_gene_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover IPTG Response Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "StateLinearDictionary = [lambda x:x[elem] for elem in np.arange(0,len(common_indices),1)];\n",
    "StateLifting = Lifting(np.arange(1,len(common_indices),1),StateLinearDictionary,len(common_indices))\n",
    "KM = InputKoopmanModel(this_K,StateLifting,None,None)\n",
    "\n",
    "InputQuadraticDictionary = []\n",
    "for elem in np.arange(0,len(common_indices),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']*x[-1]')\n",
    "    InputQuadraticDictionary.append(g);\n",
    "\n",
    "InputQuadraticDictionary = InputQuadraticDictionary+[lambda xu:xu[-1]]; \n",
    "\n",
    "InputLifting = Lifting(np.arange(0,len(InputQuadraticDictionary)),InputQuadraticDictionary,len(InputQuadraticDictionary))\n",
    "\n",
    "# %autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['01']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "# this_strain_id = 'MG1655_IcaR_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer1 = MinMaxScaler(feature_range=(-1,1)).fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = MinMaxScaler(feature_range=(-1,1)).fit(T2_list_raw)\n",
    "T2_list =  transformer1.transform(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "# import sklearn;\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# transformer1 = Normalizer().fit(T1_list_raw)\n",
    "# T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "# transformer2 = Normalizer().fit(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp = np.zeros( (InputLifting.return_dim(),Up_data.shape[1]));\n",
    "for ind in range(0,Up_data.shape[1]):\n",
    "    xu_vec = np.vstack((Yp_data[:,ind].reshape((len(Yp_data[:,ind]),1)),Up_data[:,ind].reshape(len(Up_data[:,ind]),1)))\n",
    "    PsiUp[:,ind] = InputLifting.eval_lifting_array(xu_vec).flatten();\n",
    "\n",
    "\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "    \n",
    "Ki = calc_Input_Koopman(KM.Kol,Yf_data,Yp_data,PsiUp,flag=2,lambda_val=0.001)\n",
    "KM.K_input = Ki;\n",
    "KM.Ki = Ki;\n",
    "\n",
    "KM.Psi_input = InputLifting;\n",
    "KM.Pi = InputLifting;\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(1,5))\n",
    "sns.set(font_scale=1.0)\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "sns.heatmap(Ki[:,Ki.shape[1]-1].reshape(-1,1),cmap='Spectral',xticklabels=['IPTG'],yticklabels=all_gene_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define PhlF (IPTG) Gate Lifting and Input-Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "InputLinearDictionary = [None]*len(all_genes)\n",
    "for elem in np.arange(0,len(all_genes),1):\n",
    "    exec('g= lambda x:x[' + repr(elem) + ']')\n",
    "    InputLinearDictionary[elem] = g;\n",
    "     \n",
    "\n",
    "InputLifting = Lifting(np.arange(4098,4136,1),InputLinearDictionary,len(all_genes)-4098)\n",
    "\n",
    "# %autoreload\n",
    "viz_this_set = False; \n",
    "timepair_list = [];\n",
    "for ind_cond in ['01']:\n",
    "    for temp in ['37']:\n",
    "        for replicate_ind in ['0','1','2','3']:\n",
    "            pair_string = [ind_cond+temp+'5'+replicate_ind,ind_cond+temp+'18'+replicate_ind];\n",
    "            timepair_list.append(pair_string);\n",
    "            \n",
    "#this_strain_id = 'MG1655_WT'\n",
    "#this_strain_id = 'MG1655_NAND_Circuit'\n",
    "#this_strain_id = 'MG1655_pJS007_LALT__P3__PhlF'\n",
    "# this_strain_id = 'MG1655_IcaR_Gate'\n",
    "this_strain_id = 'MG1655_PhlF_Gate'\n",
    "timepoint_5hr_index = 0; \n",
    "timepoint_18hr_index = 1; \n",
    "T1_list = [];\n",
    "T2_list = [];\n",
    "for pair_tuple in timepair_list:\n",
    "    x_vec = master_dict[this_strain_id][pair_tuple[timepoint_5hr_index]][0]\n",
    "    y_vec = master_dict[this_strain_id][pair_tuple[timepoint_18hr_index]][0];\n",
    "    \n",
    "    T1_list.append(x_vec);\n",
    "    T2_list.append(y_vec);\n",
    "    \n",
    "\n",
    "T1_list = np.asarray(T1_list,dtype=np.float32)\n",
    "T2_list = np.asarray(T2_list,dtype=np.float32)\n",
    "\n",
    "T1_list_raw = T1_list; \n",
    "T2_list_raw = T2_list;\n",
    "\n",
    "import sklearn;\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transformer1 = MinMaxScaler(feature_range=(-1,1)).fit(T1_list_raw)\n",
    "T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "transformer2 = MinMaxScaler(feature_range=(-1,1)).fit(T2_list_raw)\n",
    "T2_list =  transformer1.transform(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "# import sklearn;\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "# transformer1 = Normalizer().fit(T1_list_raw)\n",
    "# T1_list = transformer1.transform(T1_list_raw)\n",
    "\n",
    "# transformer2 = Normalizer().fit(T2_list_raw)\n",
    "# T2_list =  transformer2.transform(T2_list_raw)\n",
    "\n",
    "T1_list_log_norm = T1_list;\n",
    "T2_list_log_norm = T2_list;\n",
    "\n",
    "#T1_list_log = np.log10(T1_list);\n",
    "#T1_list_log[T1_list_log==-np.Inf] = 0.0;\n",
    "#T2_list_log = np.log10(T2_list);\n",
    "#T2_list_log[T2_list_log==-np.Inf] = 0.0;\n",
    "\n",
    "#T1_list = T1_list_log;\n",
    "#T2_list = T2_list_log;\n",
    "\n",
    "low_cv_reps = [0,2,3]\n",
    "col_ind_map = [0,0,1,2]\n",
    "\n",
    "if viz_this_set:\n",
    "    mu_t1 = np.mean(T1_list[low_cv_reps][:],axis=0);\n",
    "    s_t1 = np.std(T1_list[low_cv_reps][:],axis=0);\n",
    "\n",
    "    mu_t2 = np.mean(T2_list[low_cv_reps][:],axis=0);\n",
    "    s_t2 = np.std(T2_list[low_cv_reps][:],axis=0);\n",
    "    cv1 = mu_t1-mu_t1;\n",
    "    cv2 = mu_t2-mu_t2;\n",
    "    plt.figure()\n",
    "    plt.scatter((mu_t1[low_cv_indices]),(mu_t2[low_cv_indices]))\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.figure()\n",
    "    plt.scatter(mu_t1,mu_t2)\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.xlim([0.0,1.0])\n",
    "\n",
    "\n",
    "Yp_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Yf_data = np.zeros((len(common_indices),len(low_cv_reps)))\n",
    "Up_data = 1e0*np.ones((1,len(low_cv_reps)));\n",
    "PsiUp_Gate = np.zeros( (InputLifting.return_dim(),len(low_cv_reps)));\n",
    "for ind in range(0,len(low_cv_reps)):\n",
    "    PsiUp_Gate[:,ind] = InputLifting.eval_lifting_array(T1_list.T[:,ind]).flatten();\n",
    "\n",
    "\n",
    "for col_ind in low_cv_reps:\n",
    "    Yp_data[:,col_ind_map[col_ind]] = T1_list_log_norm.T[common_indices,col_ind];\n",
    "    Yf_data[:,col_ind_map[col_ind]]= T2_list_log_norm.T[common_indices,col_ind];\n",
    "\n",
    "\n",
    "    \n",
    "Ki = calc_Append_Input_Koopman(KM.Kol,KM.Ki,Yf_data,Yp_data,PsiUp,PsiUp_Gate,flag=2,lambda_val=0.1)\n",
    "\n",
    "\n",
    "KM.append_input(Ki,InputLifting)\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.set(font_scale=1.0)\n",
    "all_gene_labels = [all_genes[elem] for elem in common_indices]\n",
    "\n",
    "sns.heatmap(Ki,cmap='twilight',xticklabels=Circuit_Gene_Names,yticklabels=all_gene_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as spl\n",
    "sparse_K = sp.coo_matrix(this_K)\n",
    "d,v = spl.eigs(sparse_K,k=10)\n",
    "\n",
    "list_all_genes = list(all_genes);\n",
    "for row_ind in range(0,this_K.shape[0]):\n",
    "    for col_ind in range(0,this_K.shape[1]):\n",
    "        if (np.abs(this_K[row_ind][col_ind]) >5e-1) and (row_ind != col_ind):\n",
    "            #if common_indices[col_ind] in circuit_ids or common_indices[row_ind] in circuit_ids:\n",
    "                print(list_all_genes[common_indices[row_ind]] + \" is affected by \" +list_all_genes[common_indices[col_ind]])\n",
    "\n",
    "\n",
    "circuit_to_host_K = this_K[:,circuit_coords_in_K]\n",
    "#print(circuit_to_host_K[circuit_to_host_K>5e-11])\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "host_to_circuit_K = this_K[circuit_coords_in_K,:]\n",
    "#print(host_to_circuit_K[host_to_circuit_K>5e-11])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
