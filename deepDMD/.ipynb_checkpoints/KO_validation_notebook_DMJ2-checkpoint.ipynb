{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import tensorflow as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "sess  = tf.compat.v1.InteractiveSession()\n",
    "from scipy.integrate import odeint\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.signal import savgol_filter\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1 = tf.compat.v1.InteractiveSession()\n",
    "saver = tf.compat.v1.train.import_meta_graph('Checkpoint_files/CFS_Koopman_correct_ics2.pickle.ckpt.meta', clear_devices=True)\n",
    "saver.restore(sess1, tf.train.latest_checkpoint('Checkpoint_files'))\n",
    "\n",
    "scaler = joblib.load(scaler_filename) \n",
    "\n",
    "psixpT = tf.compat.v1.get_collection('psiyp')[0]\n",
    "psixfT = tf.compat.v1.get_collection('psiyf')[0]\n",
    "xpT_feed = tf.compat.v1.get_collection('yp_feed')[0]\n",
    "xfT_feed = tf.compat.v1.get_collection('yf_feed')[0]\n",
    "KxT = tf.compat.v1.get_collection('Kx')[0]\n",
    "KxT_num = sess1.run(KxT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "Xp_final_learned = []\n",
    "Xf_final_learned = []\n",
    "Xp_final_actual = []\n",
    "Xf_final_actual = []\n",
    "t = np.array([i for i in range(0, N+1)])\n",
    "x_learned = np.zeros(2)\n",
    "x_actual = np.zeros(2)\n",
    "for ic in ICs:\n",
    "    ic_s = scaler.transform(np.array([ic]))\n",
    "    x_learned = np.array(ic_s)\n",
    "    x_actual[0] = ic[0]\n",
    "    x_actual[1] = ic[1]\n",
    "    X_learned = []\n",
    "    X_actual = []\n",
    "    X_learned.append([x_learned[0][0], x_learned[0][1]]) ## ICs\n",
    "    X_actual.append(np.array([x_actual[0], x_actual[1]])) \n",
    "    for k in range(0, N):\n",
    "        y_learned = np.matmul(KxT_num.T, psixpT.eval(feed_dict={xpT_feed: x_learned}).T)[0:2].T\n",
    "        x_learned = y_learned\n",
    "        X_learned.append([x_learned[0][0], x_learned[0][1]]) \n",
    "        #print(k)\n",
    "        y_actual = model(x_actual)\n",
    "        x_actual = y_actual\n",
    "        X_actual.append([x_actual[0], x_actual[1]])\n",
    "    Xp_learned = X_learned[0:-1]\n",
    "    Xf_learned = X_learned[1:]\n",
    "    Xp_actual = X_actual[0:-1]\n",
    "    Xf_actual = X_actual[1:]   \n",
    "    X_learned = scaler.inverse_transform(X_learned)\n",
    "    plt.scatter(t, np.array(X_actual).T[0])\n",
    "    plt.plot(t, np.array(X_learned).T[0])\n",
    "    Xp_final_learned = Xp_final_learned + Xp_learned\n",
    "    Xf_final_learned = Xf_final_learned + Xf_learned\n",
    "    Xp_final_actual = Xp_final_actual + Xp_actual\n",
    "    Xf_final_actual = Xf_final_actual + Xf_actual\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "N = 20\n",
    "Xp_final_learned = []\n",
    "Xf_final_learned = []\n",
    "Xp_final_actual = []\n",
    "Xf_final_actual = []\n",
    "t = np.array([i for i in range(0, N+1)])\n",
    "x_learned = np.zeros(2)\n",
    "x_actual = np.zeros(2)\n",
    "for ic in ICs:\n",
    "    ic_s = scaler.transform(np.array([ic]))\n",
    "    x_learned = np.array(ic_s)\n",
    "    x_actual[0] = ic[0]\n",
    "    x_actual[1] = ic[1]\n",
    "    X_learned = []\n",
    "    X_actual = []\n",
    "    X_learned.append([x_learned[0][0], x_learned[0][1]]) ## ICs\n",
    "    X_actual.append(np.array([x_actual[0], x_actual[1]])) \n",
    "    for k in range(0, N):\n",
    "        y_learned = np.matmul(KxT_num.T, psixpT.eval(feed_dict={xpT_feed: x_learned}).T)[0:2].T\n",
    "        x_learned = y_learned\n",
    "        X_learned.append([x_learned[0][0], x_learned[0][1]]) \n",
    "        #print(k)\n",
    "        y_actual = model(x_actual)\n",
    "        x_actual = y_actual\n",
    "        X_actual.append([x_actual[0], x_actual[1]])\n",
    "    Xp_learned = X_learned[0:-1]\n",
    "    Xf_learned = X_learned[1:]\n",
    "    Xp_actual = X_actual[0:-1]\n",
    "    Xf_actual = X_actual[1:]   \n",
    "    X_learned = scaler.inverse_transform(X_learned)\n",
    "    plt.scatter(t, np.array(X_actual).T[1])\n",
    "    plt.plot(t, np.array(X_learned).T[1])\n",
    "    Xp_final_learned = Xp_final_learned + Xp_learned\n",
    "    Xf_final_learned = Xf_final_learned + Xf_learned\n",
    "    Xp_final_actual = Xp_final_actual + Xp_actual\n",
    "    Xf_final_actual = Xf_final_actual + Xf_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "scale = 1\n",
    "if scale:\n",
    "    Xp_final_learned_scaled = scaler.inverse_transform(Xp_final_learned)\n",
    "    Xf_final_learned_scaled = scaler.inverse_transform(Xf_final_learned)\n",
    "else:\n",
    "    Xp_final_learned_scaled = np.array(Xp_final_learned)\n",
    "    Xf_final_learned_scaled = np.array(Xf_final_learned)\n",
    "    \n",
    "#pickle.dump([Xp_ref_scaled, Xf_ref_scaled, Up_ref], open('/Users/dennisjoshy/Documents/darpa-sd2/deepDMD/koopman_data/CFS_Koopman_correct_ics2.pickle', 'wb'),  protocol = 2)\n",
    "\n",
    "plt.scatter(np.linspace(0, len(Xp_final_learned_scaled[:, 0]), len(Xp_final_learned_scaled[:, 0])), Xp_final_learned_scaled[:, 0])\n",
    "plt.scatter(np.linspace(0, len(Xf_final_learned_scaled[:, 0]), len(Xf_final_learned_scaled[:, 0])), Xf_final_learned_scaled[:, 0])\n",
    "\n",
    "plt.scatter(np.linspace(0, len(np.array(Xp_final_actual)[:, 0]), len(np.array(Xp_final_actual)[:, 0])), np.array(Xp_final_actual)[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scale = 1\n",
    "scaler = StandardScaler().fit(Xp_final_learned)\n",
    "if scale:\n",
    "    Xp_final_learned_scaled = scaler.inverse_transform(Xp_final_learned)\n",
    "    Xf_final_learned_scaled = scaler.inverse_transform(Xf_final_learned)\n",
    "else:\n",
    "    Xp_final_learned_scaled = np.array(Xp_final_learned)\n",
    "    Xf_final_learned_scaled = np.array(Xf_final_learned)\n",
    "    \n",
    "#pickle.dump([Xp_ref_scaled, Xf_ref_scaled, Up_ref], open('/Users/dennisjoshy/Documents/darpa-sd2/deepDMD/koopman_data/CFS_Koopman_correct_ics2.pickle', 'wb'),  protocol = 2)\n",
    "\n",
    "#plt.scatter(np.linspace(0, len(Xp_final_learned_scaled[:, 1]), len(Xp_final_learned_scaled[:, 1])), Xp_final_learned_scaled[:, 1])\n",
    "plt.scatter(np.linspace(0, len(Xf_final_learned_scaled[:, 1]), len(Xf_final_learned_scaled[:, 1])), Xf_final_learned_scaled[:, 1])\n",
    "\n",
    "plt.scatter(np.linspace(0, len(np.array(Xf_final_actual)[:, 1]), len(np.array(Xf_final_actual)[:, 1])), np.array(Xf_final_actual)[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
